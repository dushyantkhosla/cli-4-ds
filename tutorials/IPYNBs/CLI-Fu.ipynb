{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README\n",
    "\n",
    "---\n",
    "\n",
    "This document serves as an accompanying guide/index to the command-line tools discussed in the notebooks. Here we have presented the relevant functions/verbs from command-line-tools that work with tabular data in the context of data-analysis tasks.\n",
    "\n",
    "Expand each section for names of functions that help in performing said task, then access the respective notebook for specific examples.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# $00 - Import, Inspect$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## `conversion`\n",
    "\n",
    "- _from/to csv_\n",
    "\n",
    "---\n",
    "\n",
    "```bash\n",
    "in2csv, csv2json\n",
    "csvtk csv2tab, space2tab, tab2csv\n",
    "xsv fmt\n",
    "mlr cat\n",
    "\n",
    "## compressed data?\n",
    "mlr --prepipe\n",
    "```\n",
    "\n",
    "---\n",
    "## `display`\n",
    "\n",
    "```bash\n",
    "head, tail\n",
    "csvlook\n",
    "csvtk pretty\n",
    "xsv table\n",
    "mlr head, tail\n",
    "```\n",
    "\n",
    "---\n",
    "## `count`\n",
    "\n",
    "- _rows, columns_\n",
    "\n",
    "```bash\n",
    "wc\n",
    "xsv count\n",
    "```\n",
    "\n",
    "---\n",
    "## `types`\n",
    "\n",
    "- _detect types, conversion_\n",
    "\n",
    "---\n",
    "\n",
    "```bash\n",
    "mlr put is_*\n",
    "mlr put boolean, int, float, string\n",
    "```\n",
    "\n",
    "---\n",
    "## `column names`\n",
    "\n",
    "```bash\n",
    "csvcut -n\n",
    "xsv headers\n",
    "csvtk headers\n",
    "mlr label\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# $01 - Subset$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "## `rename`\n",
    "\n",
    "-  _one/many columns_\n",
    "\n",
    "\n",
    "\n",
    "```bash\n",
    "csvtk rename, rename2\n",
    "mlr rename\n",
    "```\n",
    "\n",
    "---\n",
    "## `index`\n",
    "\n",
    "- _create row names/indentifiers_\n",
    "\n",
    "\n",
    "\n",
    "```bash\n",
    "nl\n",
    "xsv index\n",
    "```\n",
    "\n",
    "---\n",
    "## `subset columns` \n",
    "\n",
    "- _select/exclude cols_\n",
    "\n",
    "\n",
    "```bash\n",
    "cut\n",
    "csvcut\n",
    "csvtk select\n",
    "xsv select\n",
    "mlr cut\n",
    "mlr having-fields\n",
    "```\n",
    "\n",
    "---\n",
    "## `subset rows` \n",
    "\n",
    "- _select/exclude rows_\n",
    "\n",
    "```bash\n",
    "cut\n",
    "csvgrep\n",
    "csvtk filter, filter2, grep\n",
    "xsv search\n",
    "mlr filter\n",
    "```\n",
    "\n",
    "---\n",
    "## `sample`\n",
    "\n",
    "- _with (bootstrap) or without replacement (permutation)_\n",
    "\n",
    "\n",
    "```bash\n",
    "shuf\n",
    "csvtk sample\n",
    "xsv sample\n",
    "mlr bootstrap, sample, shuffle, decimate\n",
    "```\n",
    "\n",
    "---\n",
    "## `split`\n",
    "\n",
    "- _large file into smaller files_\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "```bash\n",
    "split\n",
    "csplit\n",
    "xsv split\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# $02-Clean$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## `missing`\n",
    "\n",
    "\n",
    "## _detect, count, replace_\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "```bash\n",
    "awk\n",
    "csvstat --nulls\n",
    "mlr put is_null, is_not_null\n",
    "```\n",
    "\n",
    "## `duplicates`\n",
    "\n",
    "## _identify, remove dups_\n",
    "\n",
    "---\n",
    "\n",
    "```bash\n",
    "mlr repeat # create dups\n",
    "datamash rmdup\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# $03-Mutate$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "\n",
    "## `mutate`\n",
    "\n",
    "- _create/drop rows, cols_\n",
    "\n",
    "\n",
    "```bash\n",
    "awk\n",
    "mlr put\n",
    "csvtk mutate\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## `format`\n",
    "\n",
    "- _numerical formatting_\n",
    "\n",
    "```bash\n",
    "numfmt\n",
    "datamash round, ceil, floor, trunc, frac\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## `time conversions`\n",
    "\n",
    "-  _from/to epoch_\n",
    "\n",
    "```bash\n",
    "mlr put with strftime, strptime\n",
    "mlr sec2gmt, sec2gmtdate\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## `functions`\n",
    "\n",
    "- _apply, map_\n",
    "\n",
    "\n",
    "```bash\n",
    "awk\n",
    "mlr put\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## `discretize`\n",
    "\n",
    "\n",
    "- _cut numerics into categoricals_\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "```bash\n",
    "datamash bin\n",
    "mlr histogram --nbins\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## `reshape`\n",
    "\n",
    "\n",
    "- _long/wide to wide/long_\n",
    "\n",
    "\n",
    "```bash\n",
    "paste\n",
    "csvtk transpose\n",
    "datamash transpose\n",
    "\n",
    "# pandas-like reshape\n",
    "mlr reshape\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# $04-Merge/Join/Concat$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "## ` join`\n",
    "\n",
    "- _merge tables_\n",
    "\n",
    "\n",
    "```bash\n",
    "join\n",
    "csvtk join\n",
    "xsv join\n",
    "```\n",
    "\n",
    "---\n",
    "## `concat`\n",
    "\n",
    "- _append/concat tables_\n",
    "\n",
    "\n",
    "```bash\n",
    "cat\n",
    "csvstack\n",
    "xsv cat\n",
    "\n",
    "# concat when cols are not same\n",
    "mlr unsparsify\n",
    "```\n",
    "\n",
    "---\n",
    "## ` compare, intersect`\n",
    "\n",
    "- _rows in A & B, rows in A not in B etc._\n",
    "\n",
    "\n",
    "```bash\n",
    "comm\n",
    "csvtk intersect\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# $05-Explore$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## `aggregate`\n",
    "\n",
    "- _group-by, pivot_\n",
    "\n",
    "\n",
    "```bash\n",
    "datamash\n",
    "mlr\n",
    "```\n",
    "\n",
    "---\n",
    "## `sort`\n",
    "\n",
    "```bash\n",
    "sort\n",
    "csvsort\n",
    "```\n",
    "\n",
    "---\n",
    "## `uniques`\n",
    "\n",
    "\n",
    "\n",
    "```bash\n",
    "uniq\n",
    "csvtk uniq\n",
    "```\n",
    "\n",
    "---\n",
    "## `frequencies`\n",
    "\n",
    "\n",
    "```bash\n",
    "uniq -c\n",
    "csvtk freq\n",
    "xsv frequency\n",
    "mlr top\n",
    "mlr least-frequent, most-frequent\n",
    "mlr fraction # convert frequencies to percentages\n",
    "```\n",
    "\n",
    "---\n",
    "## `crosstabs`\n",
    "\n",
    "\n",
    "```bash\n",
    "datamash crosstab\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# $06-Analyze/Visualize$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "## `univariate`\n",
    "\n",
    "- _mean/stddev, median, percentiles, skewness/kurtosis, mode, min/max_\n",
    "\n",
    "```bash\n",
    "csvstat\n",
    "csvtk stats, stats2\n",
    "xsv stats\n",
    "mlr stats1, stats2\n",
    "datamash\n",
    "```\n",
    "\n",
    "---\n",
    "## `bivariate`\n",
    "\n",
    "- _correlation/covariance, regression, r-squared_\n",
    "\n",
    "```bash\n",
    "mlr stats2\n",
    "```\n",
    "\n",
    "---\n",
    "## `visualize`\n",
    "\n",
    "- _histograms, scatterplots_\n",
    "\n",
    "```bash\n",
    "csvtk plot\n",
    "mlr bar\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# $07-Advanced$\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "## `generate`\n",
    "\n",
    "\n",
    "- _random data_\n",
    "\n",
    "```\n",
    "seq, shuf, pr\n",
    "mlr seqgen\n",
    "mlr put \"urand(), urandint()\"\n",
    "```\n",
    "\n",
    "---\n",
    "## `query`\n",
    "\n",
    "\n",
    "- _run sql queries_\n",
    "\n",
    "```bash\n",
    "csvsql\n",
    "q -H -d, \"\"\"query\"\"\"\n",
    "\n",
    "# generate a CREATE TABLE query for your csv\n",
    "# super useful when pushing data into a local db (mysql, postgresql etc.)\n",
    "csvsql -i sqlite joined.csv\n",
    "```\n",
    "\n",
    "----\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Appendix$\n",
    "\n",
    "---\n",
    "\n",
    "Expand the sections below to read through the help pages of these tools and for a list of the most frequently used verbs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## `datamash`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "```bash\n",
    "Primary operations:\n",
    "  groupby, crosstab, transpose, reverse, check\n",
    "  \n",
    "Line-Filtering operations:\n",
    "  rmdup\n",
    "\n",
    "Per-Line operations:\n",
    "  base64, debase64, md5, sha1, sha256, sha512,\n",
    "  bin, strbin, round, floor, ceil, trunc, frac\n",
    "\n",
    "Numeric Grouping operations:\n",
    "  sum, min, max, absmin, absmax\n",
    "\n",
    "Textual/Numeric Grouping operations:\n",
    "  count, first, last, rand, unique, collapse, countunique\n",
    "\n",
    "Statistical Grouping operations:\n",
    "  mean, median, q1, q3, iqr, mode, antimode, pstdev, sstdev, pvar,\n",
    "  svar, mad, madraw, pskew, sskew, pkurt, skurt, dpo, jarque,\n",
    "  scov, pcov, spearson, ppearson\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: datamash [OPTION] op [fld] [op fld ...]\n",
      "\n",
      "Performs numeric/string operations on input from stdin.\n",
      "\n",
      "'op' is the operation to perform.  If a primary operation is used,\n",
      "it must be listed first, optionally followed by other operations.\n",
      "'fld' is the input field to use.  'fld' can be a number (1=first field),\n",
      "or a field name when using the -H or --header-in options.\n",
      "Multiple fields can be listed with a comma (e.g. 1,6,8).  A range of\n",
      "fields can be listed with a dash (e.g. 2-8).  Use colons for operations\n",
      "which require a pair of fields (e.g. 'pcov 2:6').\n",
      "\n",
      "\n",
      "Primary operations:\n",
      "  groupby, crosstab, transpose, reverse, check\n",
      "Line-Filtering operations:\n",
      "  rmdup\n",
      "Per-Line operations:\n",
      "  base64, debase64, md5, sha1, sha256, sha512,\n",
      "  bin, strbin, round, floor, ceil, trunc, frac\n",
      "Numeric Grouping operations:\n",
      "  sum, min, max, absmin, absmax\n",
      "Textual/Numeric Grouping operations:\n",
      "  count, first, last, rand, unique, collapse, countunique\n",
      "Statistical Grouping operations:\n",
      "  mean, median, q1, q3, iqr, mode, antimode, pstdev, sstdev, pvar,\n",
      "  svar, mad, madraw, pskew, sskew, pkurt, skurt, dpo, jarque,\n",
      "  scov, pcov, spearson, ppearson\n",
      "\n",
      "\n",
      "Grouping Options:\n",
      "  -f, --full                print entire input line before op results\n",
      "                              (default: print only the grouped keys)\n",
      "  -g, --group=X[,Y,Z]       group via fields X,[Y,Z];\n",
      "                              equivalent to primary operation 'groupby'\n",
      "      --header-in           first input line is column headers\n",
      "      --header-out          print column headers as first line\n",
      "  -H, --headers             same as '--header-in --header-out'\n",
      "  -i, --ignore-case         ignore upper/lower case when comparing text;\n",
      "                              this affects grouping, and string operations\n",
      "  -s, --sort                sort the input before grouping; this removes the\n",
      "                              need to manually pipe the input through 'sort'\n",
      "File Operation Options:\n",
      "      --no-strict           allow lines with varying number of fields\n",
      "      --filler=X            fill missing values with X (default %s)\n",
      "\n",
      "General Options:\n",
      "  -t, --field-separator=X   use X instead of TAB as field delimiter\n",
      "      --narm                skip NA/NaN values\n",
      "  -W, --whitespace          use whitespace (one or more spaces and/or tabs)\n",
      "                              for field delimiters\n",
      "  -z, --zero-terminated     end lines with 0 byte, not newline\n",
      "      --help     display this help and exit\n",
      "      --version  output version information and exit\n",
      "\n",
      "\n",
      "Examples:\n",
      "\n",
      "Print the sum and the mean of values from column 1:\n",
      "  $ seq 10 | datamash sum 1 mean 1\n",
      "  55  5.5\n",
      "\n",
      "Transpose input:\n",
      "  $ seq 10 | paste - - | datamash transpose\n",
      "  1    3    5    7    9\n",
      "  2    4    6    8    10\n",
      "\n",
      "For detailed usage information and examples, see\n",
      "  man GNU datamash\n",
      "The manual and more examples are available at\n",
      "  http://www.gnu.org/software/datamash\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!datamash --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## `mlr`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "```bash\n",
    "Verbs\n",
    "\n",
    "   bar bootstrap cat check count-distinct cut decimate filter grep group-by\n",
    "   group-like having-fields head histogram join label least-frequent\n",
    "   merge-fields most-frequent nest nothing fraction put regularize rename\n",
    "   reorder repeat reshape sample sec2gmt sec2gmtdate seqgen shuffle sort stats1\n",
    "   stats2 step tac tail tee top uniq unsparsify\n",
    "\n",
    "   Use \"mlr {verb} -h\" for help\n",
    "\n",
    "Functions (for the `filter` and `put` verbs)\n",
    "\n",
    "    # arithmetic, logical, conditional operators\n",
    "   + + - - * / // % ** | ^ & ~ << >> == != =~ !=~ > >= < <= && || ^^ ! ? : .\n",
    "   \n",
    "   # string functions\n",
    "   gsub strlen sub substr tolower toupper   \n",
    "   \n",
    "   # math\n",
    "   abs ceil floor log log10 log1p\n",
    "   max min msub exp pow qnorm  \n",
    "   sgn sqrt cbrt\n",
    "   \n",
    "   # random numbers\n",
    "   urand urand32 urandint \n",
    " \n",
    "   # date, time\n",
    "   dhms2fsec dhms2sec fsec2dhms fsec2hms\n",
    "   gmt2sec hms2fsec hms2sec sec2dhms sec2gmt sec2gmt sec2gmtdate sec2hms\n",
    "   strftime strptime systime \n",
    "   \n",
    "   # booleans\n",
    "   is_absent is_bool is_boolean is_empty is_empty_map\n",
    "   is_float is_int is_map is_nonempty_map is_not_empty is_not_map is_not_null\n",
    "   is_null is_numeric is_present is_string \n",
    "  \n",
    "   # type-conversoin, rounding, formatting \n",
    "   boolean float int string\n",
    "   round roundm\n",
    "   fmtnum hexfmt \n",
    "   \n",
    "Use \"mlr --help-function {function name}\" for function-specific help.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: mlr [I/O options] {verb} [verb-dependent options ...] {zero or more file names}\n",
      "\n",
      "Command-line-syntax examples:\n",
      "  mlr --csv cut -f hostname,uptime mydata.csv\n",
      "  mlr --tsv --rs lf filter '$status != \"down\" && $upsec >= 10000' *.tsv\n",
      "  mlr --nidx put '$sum = $7 < 0.0 ? 3.5 : $7 + 2.1*$8' *.dat\n",
      "  grep -v '^#' /etc/group | mlr --ifs : --nidx --opprint label group,pass,gid,member then sort -f group\n",
      "  mlr join -j account_id -f accounts.dat then group-by account_name balances.dat\n",
      "  mlr --json put '$attr = sub($attr, \"([0-9]+)_([0-9]+)_.*\", \"\\1:\\2\")' data/*.json\n",
      "  mlr stats1 -a min,mean,max,p10,p50,p90 -f flag,u,v data/*\n",
      "  mlr stats2 -a linreg-pca -f u,v -g shape data/*\n",
      "  mlr put -q '@sum[$a][$b] += $x; end {emit @sum, \"a\", \"b\"}' data/*\n",
      "  mlr --from estimates.tbl put '\n",
      "  for (k,v in $*) {\n",
      "    if (is_numeric(v) && k =~ \"^[t-z].*$\") {\n",
      "      $sum += v; $count += 1\n",
      "    }\n",
      "  }\n",
      "  $mean = $sum / $count # no assignment if count unset'\n",
      "  mlr --from infile.dat put -f analyze.mlr\n",
      "  mlr --from infile.dat put 'tee > \"./taps/data-\".$a.\"-\".$b, $*'\n",
      "  mlr --from infile.dat put 'tee | \"gzip > ./taps/data-\".$a.\"-\".$b.\".gz\", $*'\n",
      "  mlr --from infile.dat put -q '@v=$*; dump | \"jq .[]\"'\n",
      "  mlr --from infile.dat put  '(NR % 1000 == 0) { print > stderr, \"Checkpoint \".NR}'\n",
      "\n",
      "Data-format examples:\n",
      "  DKVP: delimited key-value pairs (Miller default format)\n",
      "  +---------------------+\n",
      "  | apple=1,bat=2,cog=3 | Record 1: \"apple\" => \"1\", \"bat\" => \"2\", \"cog\" => \"3\"\n",
      "  | dish=7,egg=8,flint  | Record 2: \"dish\" => \"7\", \"egg\" => \"8\", \"3\" => \"flint\"\n",
      "  +---------------------+\n",
      "\n",
      "  NIDX: implicitly numerically indexed (Unix-toolkit style)\n",
      "  +---------------------+\n",
      "  | the quick brown     | Record 1: \"1\" => \"the\", \"2\" => \"quick\", \"3\" => \"brown\"\n",
      "  | fox jumped          | Record 2: \"1\" => \"fox\", \"2\" => \"jumped\"\n",
      "  +---------------------+\n",
      "\n",
      "  CSV/CSV-lite: comma-separated values with separate header line\n",
      "  +---------------------+\n",
      "  | apple,bat,cog       |\n",
      "  | 1,2,3               | Record 1: \"apple => \"1\", \"bat\" => \"2\", \"cog\" => \"3\"\n",
      "  | 4,5,6               | Record 2: \"apple\" => \"4\", \"bat\" => \"5\", \"cog\" => \"6\"\n",
      "  +---------------------+\n",
      "\n",
      "  Tabular JSON: nested objects are supported, although arrays within them are not:\n",
      "  +---------------------+\n",
      "  | {                   |\n",
      "  |  \"apple\": 1,        | Record 1: \"apple\" => \"1\", \"bat\" => \"2\", \"cog\" => \"3\"\n",
      "  |  \"bat\": 2,          |\n",
      "  |  \"cog\": 3           |\n",
      "  | }                   |\n",
      "  | {                   |\n",
      "  |   \"dish\": {         | Record 2: \"dish:egg\" => \"7\", \"dish:flint\" => \"8\", \"garlic\" => \"\"\n",
      "  |     \"egg\": 7,       |\n",
      "  |     \"flint\": 8      |\n",
      "  |   },                |\n",
      "  |   \"garlic\": \"\"      |\n",
      "  | }                   |\n",
      "  +---------------------+\n",
      "\n",
      "  PPRINT: pretty-printed tabular\n",
      "  +---------------------+\n",
      "  | apple bat cog       |\n",
      "  | 1     2   3         | Record 1: \"apple => \"1\", \"bat\" => \"2\", \"cog\" => \"3\"\n",
      "  | 4     5   6         | Record 2: \"apple\" => \"4\", \"bat\" => \"5\", \"cog\" => \"6\"\n",
      "  +---------------------+\n",
      "\n",
      "  XTAB: pretty-printed transposed tabular\n",
      "  +---------------------+\n",
      "  | apple 1             | Record 1: \"apple\" => \"1\", \"bat\" => \"2\", \"cog\" => \"3\"\n",
      "  | bat   2             |\n",
      "  | cog   3             |\n",
      "  |                     |\n",
      "  | dish 7              | Record 2: \"dish\" => \"7\", \"egg\" => \"8\"\n",
      "  | egg  8              |\n",
      "  +---------------------+\n",
      "\n",
      "  Markdown tabular (supported for output only):\n",
      "  +-----------------------+\n",
      "  | | apple | bat | cog | |\n",
      "  | | ---   | --- | --- | |\n",
      "  | | 1     | 2   | 3   | | Record 1: \"apple => \"1\", \"bat\" => \"2\", \"cog\" => \"3\"\n",
      "  | | 4     | 5   | 6   | | Record 2: \"apple\" => \"4\", \"bat\" => \"5\", \"cog\" => \"6\"\n",
      "  +-----------------------+\n",
      "\n",
      "Help options:\n",
      "  -h or --help                 Show this message.\n",
      "  --version                    Show the software version.\n",
      "  {verb name} --help           Show verb-specific help.\n",
      "  --help-all-verbs             Show help on all verbs.\n",
      "  -l or --list-all-verbs       List only verb names.\n",
      "  -L                           List only verb names, one per line.\n",
      "  -f or --help-all-functions   Show help on all built-in functions.\n",
      "  -F                           Show a bare listing of built-in functions by name.\n",
      "  -k or --help-all-keywords    Show help on all keywords.\n",
      "  -K                           Show a bare listing of keywords by name.\n",
      "\n",
      "Verbs:\n",
      "   bar bootstrap cat check count-distinct cut decimate filter grep group-by\n",
      "   group-like having-fields head histogram join label least-frequent\n",
      "   merge-fields most-frequent nest nothing fraction put regularize rename\n",
      "   reorder repeat reshape sample sec2gmt sec2gmtdate seqgen shuffle sort stats1\n",
      "   stats2 step tac tail tee top uniq unsparsify\n",
      "\n",
      "Functions for the filter and put verbs:\n",
      "   + + - - * / // % ** | ^ & ~ << >> == != =~ !=~ > >= < <= && || ^^ ! ? : .\n",
      "   gsub strlen sub substr tolower toupper abs acos acosh asin asinh atan atan2\n",
      "   atanh cbrt ceil cos cosh erf erfc exp expm1 floor invqnorm log log10 log1p\n",
      "   logifit madd max mexp min mmul msub pow qnorm round roundm sgn sin sinh sqrt\n",
      "   tan tanh urand urand32 urandint dhms2fsec dhms2sec fsec2dhms fsec2hms\n",
      "   gmt2sec hms2fsec hms2sec sec2dhms sec2gmt sec2gmt sec2gmtdate sec2hms\n",
      "   strftime strptime systime is_absent is_bool is_boolean is_empty is_empty_map\n",
      "   is_float is_int is_map is_nonempty_map is_not_empty is_not_map is_not_null\n",
      "   is_null is_numeric is_present is_string asserting_absent asserting_bool\n",
      "   asserting_boolean asserting_empty asserting_empty_map asserting_float\n",
      "   asserting_int asserting_map asserting_nonempty_map asserting_not_empty\n",
      "   asserting_not_map asserting_not_null asserting_null asserting_numeric\n",
      "   asserting_present asserting_string boolean float fmtnum hexfmt int string\n",
      "   typeof depth haskey joink joinkv joinv leafcount length mapdiff mapsum\n",
      "   splitkv splitkvx splitnv splitnvx\n",
      "\n",
      "Please use \"mlr --help-function {function name}\" for function-specific help.\n",
      "\n",
      "Data-format options, for input, output, or both:\n",
      "  --idkvp   --odkvp   --dkvp      Delimited key-value pairs, e.g \"a=1,b=2\"\n",
      "                                  (this is Miller's default format).\n",
      "\n",
      "  --inidx   --onidx   --nidx      Implicitly-integer-indexed fields\n",
      "                                  (Unix-toolkit style).\n",
      "\n",
      "  --icsv    --ocsv    --csv       Comma-separated value (or tab-separated\n",
      "                                  with --fs tab, etc.)\n",
      "\n",
      "  --itsv    --otsv    --tsv       Keystroke-savers for \"--icsv --ifs tab\",\n",
      "                                  \"--ocsv --ofs tab\", \"--csv --fs tab\".\n",
      "\n",
      "  --ipprint --opprint --pprint    Pretty-printed tabular (produces no\n",
      "                                  output until all input is in).\n",
      "                      --right     Right-justifies all fields for PPRINT output.\n",
      "                      --barred    Prints a border around PPRINT output\n",
      "                                  (only available for output).\n",
      "\n",
      "            --omd                 Markdown-tabular (only available for output).\n",
      "\n",
      "  --ixtab   --oxtab   --xtab      Pretty-printed vertical-tabular.\n",
      "                      --xvright   Right-justifies values for XTAB format.\n",
      "\n",
      "  --ijson   --ojson   --json      JSON tabular: sequence or list of one-level\n",
      "                                  maps: {...}{...} or [{...},{...}].\n",
      "    --json-map-arrays-on-input    JSON arrays are unmillerable. --json-map-arrays-on-input\n",
      "    --json-skip-arrays-on-input   is the default: arrays are converted to integer-indexed\n",
      "    --json-fatal-arrays-on-input  maps. The other two options cause them to be skipped, or\n",
      "                                  to be treated as errors.  Please use the jq tool for full\n",
      "                                  JSON (pre)processing.\n",
      "                      --jvstack   Put one key-value pair per line for JSON\n",
      "                                  output.\n",
      "                      --jlistwrap Wrap JSON output in outermost [ ].\n",
      "                    --jknquoteint Do not quote non-string map keys in JSON output.\n",
      "                     --jvquoteall Quote map values in JSON output, even if they're\n",
      "                                  numeric.\n",
      "              --jflatsep {string} Separator for flattening multi-level JSON keys,\n",
      "                                  e.g. '{\"a\":{\"b\":3}}' becomes a:b => 3 for\n",
      "                                  non-JSON formats. Defaults to :.\n",
      "\n",
      "  -p is a keystroke-saver for --nidx --fs space --repifs\n",
      "\n",
      "  Examples: --csv for CSV-formatted input and output; --idkvp --opprint for\n",
      "  DKVP-formatted input and pretty-printed output.\n",
      "\n",
      "Format-conversion keystroke-saver options, for input, output, or both:\n",
      "As keystroke-savers for format-conversion you may use the following:\n",
      "  --c2t --c2d --c2n --c2j --c2x --c2p --c2m\n",
      "  --t2c       --t2d --t2n --t2j --t2x --t2p --t2m\n",
      "  --d2c --d2t       --d2n --d2j --d2x --d2p --d2m\n",
      "  --n2c --n2t --n2d       --n2j --n2x --n2p --n2m\n",
      "  --j2c --j2t --j2d --j2n       --j2x --j2p --j2m\n",
      "  --x2c --x2t --x2d --x2n --x2j       --x2p --x2m\n",
      "  --p2c --p2t --p2d --p2n --p2j --p2x       --p2m\n",
      "The letters c t d n j x p m refer to formats CSV, TSV, DKVP, NIDX, JSON, XTAB,\n",
      "PPRINT, and markdown, respectively. Note that markdown format is available for\n",
      "output only.\n",
      "\n",
      "Compressed-data options:\n",
      "  --prepipe {command} This allows Miller to handle compressed inputs. You can do\n",
      "  without this for single input files, e.g. \"gunzip < myfile.csv.gz | mlr ...\".\n",
      "  However, when multiple input files are present, between-file separations are\n",
      "  lost; also, the FILENAME variable doesn't iterate. Using --prepipe you can\n",
      "  specify an action to be taken on each input file. This pre-pipe command must\n",
      "  be able to read from standard input; it will be invoked with\n",
      "    {command} < {filename}.\n",
      "  Examples:\n",
      "    mlr --prepipe 'gunzip'\n",
      "    mlr --prepipe 'zcat -cf'\n",
      "    mlr --prepipe 'xz -cd'\n",
      "    mlr --prepipe cat\n",
      "  Note that this feature is quite general and is not limited to decompression\n",
      "  utilities. You can use it to apply per-file filters of your choice.\n",
      "  For output compression (or other) utilities, simply pipe the output:\n",
      "    mlr ... | {your compression command}\n",
      "\n",
      "Separator options, for input, output, or both:\n",
      "  --rs     --irs     --ors              Record separators, e.g. 'lf' or '\\r\\n'\n",
      "  --fs     --ifs     --ofs  --repifs    Field separators, e.g. comma\n",
      "  --ps     --ips     --ops              Pair separators, e.g. equals sign\n",
      "\n",
      "  Notes about line endings:\n",
      "  * Default line endings (--irs and --ors) are \"auto\" which means autodetect from\n",
      "    the input file format, as long as the input file(s) have lines ending in either\n",
      "    LF (also known as linefeed, '\\n', 0x0a, Unix-style) or CRLF (also known as\n",
      "    carriage-return/linefeed pairs, '\\r\\n', 0x0d 0x0a, Windows style).\n",
      "  * If both irs and ors are auto (which is the default) then LF input will lead to LF\n",
      "    output and CRLF input will lead to CRLF output, regardless of the platform you're\n",
      "    running on.\n",
      "  * The line-ending autodetector triggers on the first line ending detected in the input\n",
      "    stream. E.g. if you specify a CRLF-terminated file on the command line followed by an\n",
      "    LF-terminated file then autodetected line endings will be CRLF.\n",
      "  * If you use --ors {something else} with (default or explicitly specified) --irs auto\n",
      "    then line endings are autodetected on input and set to what you specify on output.\n",
      "  * If you use --irs {something else} with (default or explicitly specified) --ors auto\n",
      "    then the output line endings used are LF on Unix/Linux/BSD/MacOSX, and CRLF on Windows.\n",
      "\n",
      "  Notes about all other separators:\n",
      "  * IPS/OPS are only used for DKVP and XTAB formats, since only in these formats\n",
      "    do key-value pairs appear juxtaposed.\n",
      "  * IRS/ORS are ignored for XTAB format. Nominally IFS and OFS are newlines;\n",
      "    XTAB records are separated by two or more consecutive IFS/OFS -- i.e.\n",
      "    a blank line. Everything above about --irs/--ors/--rs auto becomes --ifs/--ofs/--fs\n",
      "    auto for XTAB format. (XTAB's default IFS/OFS are \"auto\".)\n",
      "  * OFS must be single-character for PPRINT format. This is because it is used\n",
      "    with repetition for alignment; multi-character separators would make\n",
      "    alignment impossible.\n",
      "  * OPS may be multi-character for XTAB format, in which case alignment is\n",
      "    disabled.\n",
      "  * TSV is simply CSV using tab as field separator (\"--fs tab\").\n",
      "  * FS/PS are ignored for markdown format; RS is used.\n",
      "  * All FS and PS options are ignored for JSON format, since they are not relevant\n",
      "    to the JSON format.\n",
      "  * You can specify separators in any of the following ways, shown by example:\n",
      "    - Type them out, quoting as necessary for shell escapes, e.g.\n",
      "      \"--fs '|' --ips :\"\n",
      "    - C-style escape sequences, e.g. \"--rs '\\r\\n' --fs '\\t'\".\n",
      "    - To avoid backslashing, you can use any of the following names:\n",
      "      cr crcr newline lf lflf crlf crlfcrlf tab space comma pipe slash colon semicolon equals\n",
      "  * Default separators by format:\n",
      "      File format  RS       FS       PS\n",
      "      dkvp         auto     ,        =\n",
      "      json         auto     (N/A)    (N/A)\n",
      "      nidx         auto     space    (N/A)\n",
      "      csv          auto     ,        (N/A)\n",
      "      csvlite      auto     ,        (N/A)\n",
      "      markdown     auto     (N/A)    (N/A)\n",
      "      pprint       auto     space    (N/A)\n",
      "      xtab         (N/A)    auto     space\n",
      "\n",
      "Relevant to CSV/CSV-lite input only:\n",
      "  --implicit-csv-header Use 1,2,3,... as field labels, rather than from line 1\n",
      "                     of input files. Tip: combine with \"label\" to recreate\n",
      "                     missing headers.\n",
      "  --headerless-csv-output   Print only CSV data lines.\n",
      "\n",
      "Double-quoting for CSV output:\n",
      "  --quote-all        Wrap all fields in double quotes\n",
      "  --quote-none       Do not wrap any fields in double quotes, even if they have\n",
      "                     OFS or ORS in them\n",
      "  --quote-minimal    Wrap fields in double quotes only if they have OFS or ORS\n",
      "                     in them (default)\n",
      "  --quote-numeric    Wrap fields in double quotes only if they have numbers\n",
      "                     in them\n",
      "  --quote-original   Wrap fields in double quotes if and only if they were\n",
      "                     quoted on input. This isn't sticky for computed fields:\n",
      "                     e.g. if fields a and b were quoted on input and you do\n",
      "                     \"put '$c = $a . $b'\" then field c won't inherit a or b's\n",
      "                     was-quoted-on-input flag.\n",
      "\n",
      "Numerical formatting:\n",
      "  --ofmt {format}    E.g. %.18lf, %.0lf. Please use sprintf-style codes for\n",
      "                     double-precision. Applies to verbs which compute new\n",
      "                     values, e.g. put, stats1, stats2. See also the fmtnum\n",
      "                     function within mlr put (mlr --help-all-functions).\n",
      "                     Defaults to %lf.\n",
      "\n",
      "Other options:\n",
      "  --seed {n} with n of the form 12345678 or 0xcafefeed. For put/filter\n",
      "                     urand()/urandint()/urand32().\n",
      "  --nr-progress-mod {m}, with m a positive integer: print filename and record\n",
      "                     count to stderr every m input records.\n",
      "  --from {filename}  Use this to specify an input file before the verb(s),\n",
      "                     rather than after. May be used more than once. Example:\n",
      "                     \"mlr --from a.dat --from b.dat cat\" is the same as\n",
      "                     \"mlr cat a.dat b.dat\".\n",
      "  -n                 Process no input files, nor standard input either. Useful\n",
      "                     for mlr put with begin/end statements only. (Same as --from\n",
      "                     /dev/null.) Also useful in \"mlr -n put -v '...'\" for\n",
      "                     analyzing abstract syntax trees (if that's your thing).\n",
      "  -I                 Process files in-place. For each file name on the command\n",
      "                     line, output is written to a temp file in the same\n",
      "                     directory, which is then renamed over the original. Each\n",
      "                     file is processed in isolation: if the output format is\n",
      "                     CSV, CSV headers will be present in each output file;\n",
      "                     statistics are only over each file's own records; and so on.\n",
      "\n",
      "Then-chaining:\n",
      "Output of one verb may be chained as input to another using \"then\", e.g.\n",
      "  mlr stats1 -a min,mean,max -f flag,u,v -g color then sort -f color\n",
      "\n",
      "For more information please see http://johnkerl.org/miller/doc and/or\n",
      "http://github.com/johnkerl/miller. This is Miller version 5.1.0.\n"
     ]
    }
   ],
   "source": [
    "!mlr -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## `csvtk`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A cross-platform, efficient and practical CSV/TSV toolkit\n",
      "\n",
      "Version: 0.7.1\n",
      "\n",
      "Author: Wei Shen <shenwei356@gmail.com>\n",
      "\n",
      "Documents  : http://shenwei356.github.io/csvtk\n",
      "Source code: https://github.com/shenwei356/csvtk\n",
      "\n",
      "Attention:\n",
      "\n",
      "    1. The CSV parser requires all the lines have same number of fields/columns.\n",
      "       Even lines with spaces will cause error.\n",
      "    2. By default, csvtk thinks your files have header row, if not, switch flag \"-H\" on.\n",
      "    3. Column names better be unique.\n",
      "    4. By default, lines starting with \"#\" will be ignored, if the header row\n",
      "       starts with \"#\", please assign flag \"-C\" another rare symbol, e.g. '$'.\n",
      "    5. By default, csvtk handles CSV files, use flag \"-t\" for tab-delimited files.\n",
      "    6. If \" exists in tab-delimited files, use flag \"-l\".\n",
      "\n",
      "Usage:\n",
      "  csvtk [command]\n",
      "\n",
      "Available Commands:\n",
      "  csv2md      convert CSV to markdown format\n",
      "  csv2tab     convert CSV to tabular format\n",
      "  cut         select parts of fields\n",
      "  filter      filter rows by values of selected fields with artithmetic expression\n",
      "  filter2     filter rows by awk-like artithmetic/string expressions\n",
      "  freq        frequencies of selected fields\n",
      "  grep        grep data by selected fields with patterns/regular expressions\n",
      "  head        print first N records\n",
      "  headers     print headers\n",
      "  help        Help about any command\n",
      "  inter       intersection of multiple files\n",
      "  join        join multiple CSV files by selected fields\n",
      "  mutate      create new column from selected fields by regular expression\n",
      "  plot        plot common figures\n",
      "  pretty      convert CSV to readable aligned table\n",
      "  rename      rename column names\n",
      "  rename2     rename column names by regular expression\n",
      "  replace     replace data of selected fields by regular expression\n",
      "  sample      sampling by proportion\n",
      "  sort        sort by selected fields\n",
      "  space2tab   convert space delimited format to CSV\n",
      "  stats       summary of CSV file\n",
      "  stats2      summary of selected digital fields\n",
      "  tab2csv     convert tabular format to CSV\n",
      "  transpose   transpose CSV data\n",
      "  uniq        unique data without sorting\n",
      "  version     print version information and check for update\n",
      "\n",
      "Flags:\n",
      "  -c, --chunk-size int         chunk size of CSV reader (default 50)\n",
      "  -C, --comment-char string    lines starting with commment-character will be ignored. if your header row starts with '#', please assign \"-C\" another rare symbol, e.g. '$' (default \"#\")\n",
      "  -d, --delimiter string       delimiting character of the input CSV file (default \",\")\n",
      "  -l, --lazy-quotes            if given, a quote may appear in an unquoted field and a non-doubled quote may appear in a quoted field\n",
      "  -H, --no-header-row          specifies that the input CSV file does not have header row\n",
      "  -j, --num-cpus int           number of CPUs to use (default value depends on your computer) (default 8)\n",
      "  -D, --out-delimiter string   delimiting character of the output CSV file (default \",\")\n",
      "  -o, --out-file string        out file (\"-\" for stdout, suffix .gz for gzipped out) (default \"-\")\n",
      "  -T, --out-tabs               specifies that the output is delimited with tabs. Overrides \"-D\"\n",
      "  -t, --tabs                   specifies that the input CSV file is delimited with tabs. Overrides \"-d\"\n",
      "\n",
      "Use \"csvtk [command] --help\" for more information about a command.\n"
     ]
    }
   ],
   "source": [
    "!csvtk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## `xsv`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xsv is a suite of CSV command line utilities.\n",
      "\n",
      "Please choose one of the following commands:\n",
      "    cat         Concatenate by row or column\n",
      "    count       Count records\n",
      "    fixlengths  Makes all records have same length\n",
      "    flatten     Show one field per line\n",
      "    fmt         Format CSV output (change field delimiter)\n",
      "    frequency   Show frequency tables\n",
      "    headers     Show header names\n",
      "    help        Show this usage message.\n",
      "    index       Create CSV index for faster access\n",
      "    input       Read CSV data with special quoting rules\n",
      "    join        Join CSV files\n",
      "    sample      Randomly sample CSV data\n",
      "    search      Search CSV data with regexes\n",
      "    select      Select columns from CSV\n",
      "    slice       Slice records from CSV\n",
      "    sort        Sort CSV data\n",
      "    split       Split CSV data into many files\n",
      "    stats       Compute basic statistics\n",
      "    table       Align CSV data into columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!xsv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
