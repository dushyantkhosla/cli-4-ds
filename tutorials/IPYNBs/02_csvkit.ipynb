{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- Downloading the `flights.csv` data to be used later\n",
    "\n",
    "```bash\n",
    "# download the file \n",
    "wget http://stat-computing.org/dataexpo/2009/2007.csv.bz2\n",
    "\n",
    "# uncompress\n",
    "sudo apt install dtrx\n",
    "dtrx ~Downloads/2007.csv.bz2\n",
    "\n",
    "# count rows\n",
    "wc -l ~Downloads/2007.csv\n",
    "\n",
    "# rename\n",
    "mv ~Downloads/2007.csv ../data/raw/flights.csv\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 dk dk     1MB May 16 10:51 countrynames.csv\n",
      "-rw-rw-r-- 1 dk dk  1490MB May 16 10:51 Crimes_Chicago.csv\n",
      "-rw------- 1 dk dk   703MB May 16 10:51 Flight_Delays.csv\n",
      "-rw-rw-r-- 1 dk dk   536MB May 16 15:42 fromPandas.csv\n",
      "-rw-rw-r-- 1 dk dk     1MB May 16 10:51 het-bool.csv\n",
      "-rw-rw-r-- 1 dk dk   743MB May 16 18:59 kdd.csv\n",
      "-rw-rw-r-- 1 dk dk    29MB May 16 18:49 millionSongsSample.csv\n",
      "-rw-rw-r-- 1 dk dk 10137MB May 16 10:52 NYC__311Requests.csv\n",
      "-rw-rw-r-- 1 dk dk   152MB May 16 10:52 worldcitiespop.csv\n"
     ]
    }
   ],
   "source": [
    "ls -l ../data/raw/ --block-size=MB | grep csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# `csvkit`\n",
    "\n",
    "\n",
    "- http://csvkit.readthedocs.io/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## `csvlook`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|------+----------+-------+-------+-------+-------+-------+-------+-------+--------|\n",
      "|  C00 | D01      | C02   | D03   | D04   | A05   | A06   | B07   | A08   | C09    |\n",
      "|------+----------+-------+-------+-------+-------+-------+-------+-------+--------|\n",
      "|  PO  | Alert    | 0.08  | -0.29 | 1.04  | 0.5   | -0.19 | 0.92  | -1.18 | 0.46   |\n",
      "|  PO  | Alert    | 0.86  | 1.81  | 2.28  | 1.58  | 0.79  | 1.19  | 0.99  | -1.17  |\n",
      "|  PO  | Critical | -0.04 | 0.52  | -0.52 | 0.34  | 2.09  | -0.6  | 0.85  | -1.14  |\n",
      "|  AR  | Critical | -0.28 | 0.56  | 0.69  | 0.62  | -0.28 | -0.25 | 0.64  | -2.03  |\n",
      "|  AR  | Critical | 0.04  | -0.38 | -0.66 | -1.76 | -0.13 | 0.6   | -2.06 | 0.96   |\n",
      "|  PO  | Critical | 0.77  | 1.48  | 0.16  | -0.59 | 0.94  | 0.48  | -0.32 | -0.55  |\n",
      "|  AR  | Alert    | -0.15 | 0.03  | -2.05 | -0.56 | -1.04 | 1.29  | 0.51  | -0.01  |\n",
      "|  PO  | Alert    | -0.17 | -0.4  | -0.16 | 2.65  | -0.48 | 0.25  | -1.1  | 0.77   |\n",
      "|  AR  | Alert    | -0.57 | -0.31 | -0.14 | -2.89 | 0.52  | 0.18  | -0.03 | 0.47   |\n",
      "|------+----------+-------+-------+-------+-------+-------+-------+-------+--------|\n"
     ]
    }
   ],
   "source": [
    "!head ../data/raw/fromPandas.csv | csvlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--------------+-----+----------+-------+-------+-------+-------+-------+-------+-------+--------|\n",
      "|  line_number | C00 | D01      | C02   | D03   | D04   | A05   | A06   | B07   | A08   | C09    |\n",
      "|--------------+-----+----------+-------+-------+-------+-------+-------+-------+-------+--------|\n",
      "|  1           | PO  | Alert    | 0.08  | -0.29 | 1.04  | 0.5   | -0.19 | 0.92  | -1.18 | 0.46   |\n",
      "|  2           | PO  | Alert    | 0.86  | 1.81  | 2.28  | 1.58  | 0.79  | 1.19  | 0.99  | -1.17  |\n",
      "|  3           | PO  | Critical | -0.04 | 0.52  | -0.52 | 0.34  | 2.09  | -0.6  | 0.85  | -1.14  |\n",
      "|  4           | AR  | Critical | -0.28 | 0.56  | 0.69  | 0.62  | -0.28 | -0.25 | 0.64  | -2.03  |\n",
      "|  5           | AR  | Critical | 0.04  | -0.38 | -0.66 | -1.76 | -0.13 | 0.6   | -2.06 | 0.96   |\n",
      "|  6           | PO  | Critical | 0.77  | 1.48  | 0.16  | -0.59 | 0.94  | 0.48  | -0.32 | -0.55  |\n",
      "|  7           | AR  | Alert    | -0.15 | 0.03  | -2.05 | -0.56 | -1.04 | 1.29  | 0.51  | -0.01  |\n",
      "|  8           | PO  | Alert    | -0.17 | -0.4  | -0.16 | 2.65  | -0.48 | 0.25  | -1.1  | 0.77   |\n",
      "|  9           | AR  | Alert    | -0.57 | -0.31 | -0.14 | -2.89 | 0.52  | 0.18  | -0.03 | 0.47   |\n",
      "|--------------+-----+----------+-------+-------+-------+-------+-------+-------+-------+--------|\n"
     ]
    }
   ],
   "source": [
    "!head ../data/raw/fromPandas.csv | csvlook -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## `csvcut`\n",
    "\n",
    "For column subsetting\n",
    "\n",
    "```\n",
    "\n",
    "Options\n",
    "\n",
    "  -n, --names           Display column names and indices from the input CSV\n",
    "                        and exit.\n",
    "  -c COLUMNS, --columns COLUMNS\n",
    "                        A comma separated list of column indices or names to\n",
    "                        be extracted. Defaults to all columns.\n",
    "  -C NOT_COLUMNS, --not-columns NOT_COLUMNS\n",
    "                        A comma separated list of column indices or names to\n",
    "                        be excluded. Defaults to no columns.\n",
    "  -x, --delete-empty-rows\n",
    "                        After cutting, delete rows which are completely empty.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1: C00\n",
      "  2: D01\n",
      "  3: C02\n",
      "  4: D03\n",
      "  5: D04\n",
      "  6: A05\n",
      "  7: A06\n",
      "  8: B07\n",
      "  9: A08\n",
      " 10: C09\n"
     ]
    }
   ],
   "source": [
    "# Get column names and positions\n",
    "!csvcut -n ../data/raw/fromPandas.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--------+-------+-----+-----------|\n",
      "|  A05   | B07   | C00 | D01       |\n",
      "|--------+-------+-----+-----------|\n",
      "|  0.5   | 0.92  | PO  | Alert     |\n",
      "|  1.58  | 1.19  | PO  | Alert     |\n",
      "|  0.34  | -0.6  | PO  | Critical  |\n",
      "|  0.62  | -0.25 | AR  | Critical  |\n",
      "|  -1.76 | 0.6   | AR  | Critical  |\n",
      "|  -0.59 | 0.48  | PO  | Critical  |\n",
      "|  -0.56 | 1.29  | AR  | Alert     |\n",
      "|  2.65  | 0.25  | PO  | Alert     |\n",
      "|  -2.89 | 0.18  | AR  | Alert     |\n",
      "|--------+-------+-----+-----------|\n"
     ]
    }
   ],
   "source": [
    "# Retain named columns with -c\n",
    "!head ../data/raw/fromPandas.csv | csvcut -c A05,B07,C00,D01 | csvlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--------+-------+-----+-----------|\n",
      "|  A05   | B07   | C00 | D01       |\n",
      "|--------+-------+-----+-----------|\n",
      "|  0.5   | 0.92  | PO  | Alert     |\n",
      "|  1.58  | 1.19  | PO  | Alert     |\n",
      "|  0.34  | -0.6  | PO  | Critical  |\n",
      "|  0.62  | -0.25 | AR  | Critical  |\n",
      "|  -1.76 | 0.6   | AR  | Critical  |\n",
      "|  -0.59 | 0.48  | PO  | Critical  |\n",
      "|  -0.56 | 1.29  | AR  | Alert     |\n",
      "|  2.65  | 0.25  | PO  | Alert     |\n",
      "|  -2.89 | 0.18  | AR  | Alert     |\n",
      "|--------+-------+-----+-----------|\n"
     ]
    }
   ],
   "source": [
    "# or use positions\n",
    "!head ../data/raw/fromPandas.csv | csvcut -c 6,8,1-2 | csvlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--------+-------+-------+-------+-------+-------+-------+--------|\n",
      "|  C02   | D03   | D04   | A05   | A06   | B07   | A08   | C09    |\n",
      "|--------+-------+-------+-------+-------+-------+-------+--------|\n",
      "|  0.08  | -0.29 | 1.04  | 0.5   | -0.19 | 0.92  | -1.18 | 0.46   |\n",
      "|  0.86  | 1.81  | 2.28  | 1.58  | 0.79  | 1.19  | 0.99  | -1.17  |\n",
      "|  -0.04 | 0.52  | -0.52 | 0.34  | 2.09  | -0.6  | 0.85  | -1.14  |\n",
      "|  -0.28 | 0.56  | 0.69  | 0.62  | -0.28 | -0.25 | 0.64  | -2.03  |\n",
      "|  0.04  | -0.38 | -0.66 | -1.76 | -0.13 | 0.6   | -2.06 | 0.96   |\n",
      "|  0.77  | 1.48  | 0.16  | -0.59 | 0.94  | 0.48  | -0.32 | -0.55  |\n",
      "|  -0.15 | 0.03  | -2.05 | -0.56 | -1.04 | 1.29  | 0.51  | -0.01  |\n",
      "|  -0.17 | -0.4  | -0.16 | 2.65  | -0.48 | 0.25  | -1.1  | 0.77   |\n",
      "|  -0.57 | -0.31 | -0.14 | -2.89 | 0.52  | 0.18  | -0.03 | 0.47   |\n",
      "|--------+-------+-------+-------+-------+-------+-------+--------|\n"
     ]
    }
   ],
   "source": [
    "# Exclude named columns with -C\n",
    "!head ../data/raw/fromPandas.csv | csvcut -C C00,D01 | csvlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--------+-------+-------+-------+-------+-------+-------+--------|\n",
      "|  C02   | D03   | D04   | A05   | A06   | B07   | A08   | C09    |\n",
      "|--------+-------+-------+-------+-------+-------+-------+--------|\n",
      "|  0.08  | -0.29 | 1.04  | 0.5   | -0.19 | 0.92  | -1.18 | 0.46   |\n",
      "|  0.86  | 1.81  | 2.28  | 1.58  | 0.79  | 1.19  | 0.99  | -1.17  |\n",
      "|  -0.04 | 0.52  | -0.52 | 0.34  | 2.09  | -0.6  | 0.85  | -1.14  |\n",
      "|  -0.28 | 0.56  | 0.69  | 0.62  | -0.28 | -0.25 | 0.64  | -2.03  |\n",
      "|  0.04  | -0.38 | -0.66 | -1.76 | -0.13 | 0.6   | -2.06 | 0.96   |\n",
      "|  0.77  | 1.48  | 0.16  | -0.59 | 0.94  | 0.48  | -0.32 | -0.55  |\n",
      "|  -0.15 | 0.03  | -2.05 | -0.56 | -1.04 | 1.29  | 0.51  | -0.01  |\n",
      "|  -0.17 | -0.4  | -0.16 | 2.65  | -0.48 | 0.25  | -1.1  | 0.77   |\n",
      "|  -0.57 | -0.31 | -0.14 | -2.89 | 0.52  | 0.18  | -0.03 | 0.47   |\n",
      "|--------+-------+-------+-------+-------+-------+-------+--------|\n"
     ]
    }
   ],
   "source": [
    "# Exclude columns with -C positionally\n",
    "!head ../data/raw/fromPandas.csv | csvcut -C 1-2 | csvlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|------+----------+-------+--------|\n",
      "|  C00 | D01      | A05   | A06    |\n",
      "|------+----------+-------+--------|\n",
      "|  PO  | Alert    | 0.5   | -0.19  |\n",
      "|  PO  | Alert    | 1.58  | 0.79   |\n",
      "|  PO  | Critical | 0.34  | 2.09   |\n",
      "|  AR  | Critical | 0.62  | -0.28  |\n",
      "|  AR  | Critical | -1.76 | -0.13  |\n",
      "|  PO  | Critical | -0.59 | 0.94   |\n",
      "|  AR  | Alert    | -0.56 | -1.04  |\n",
      "|  PO  | Alert    | 2.65  | -0.48  |\n",
      "|  AR  | Alert    | -2.89 | 0.52   |\n",
      "|------+----------+-------+--------|\n"
     ]
    }
   ],
   "source": [
    "# Combinations work too\n",
    "!head ../data/raw/fromPandas.csv | csvcut -c 1-2,A05,A06 | csvlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## `csvgrep`\n",
    "\n",
    "<br>\n",
    "\n",
    "```\n",
    "Options\n",
    "\n",
    "  -c COLUMNS, --columns COLUMNS\n",
    "                        A comma separated list of column indices or names to\n",
    "                        be searched.\n",
    "  -m PATTERN, --match PATTERN\n",
    "                        The string to search for.\n",
    "  -r REGEX, --regex REGEX\n",
    "                        If specified, must be followed by a regular expression\n",
    "                        which will be tested against the specified columns.\n",
    "  -f MATCHFILE, --file MATCHFILE\n",
    "                        If specified, must be the path to a file. For each\n",
    "                        tested row, if any line in the file (stripped of line\n",
    "                        separators) is an exact match for the cell value, the\n",
    "                        row will pass.\n",
    "  -i, --invert-match    If specified, select non-matching instead of matching\n",
    "                        rows.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|------+----------+-------+-------+-------+-------+-------+-------+-------+--------|\n",
      "|  C00 | D01      | C02   | D03   | D04   | A05   | A06   | B07   | A08   | C09    |\n",
      "|------+----------+-------+-------+-------+-------+-------+-------+-------+--------|\n",
      "|  ES  | Alert    | -1.1  | -2.31 | -0.33 | 0.56  | 3.7   | -0.09 | 1.29  | 0.89   |\n",
      "|  ES  | Alert    | 0.8   | -0.34 | -1.12 | 0.88  | -1.02 | -0.22 | -1.52 | 0.38   |\n",
      "|  ES  | Alert    | 1.86  | -0.35 | -0.22 | -0.16 | -2.12 | 0.51  | -0.76 | 0.66   |\n",
      "|  ES  | Alert    | 2.33  | -0.05 | 0.31  | 0.88  | -0.47 | -0.34 | -0.16 | -0.99  |\n",
      "|  ES  | Alert    | 0.81  | 0.94  | 0.76  | 0.08  | -0.09 | -0.07 | 0.18  | 0.4    |\n",
      "|  ES  | Critical | -0.66 | 0.17  | 1.49  | -1.5  | -0.79 | 1.77  | -0.07 | -0.82  |\n",
      "|  ES  | Alert    | -0.27 | 0.31  | -0.05 | 0.14  | -0.17 | -0.1  | 1.96  | 0.65   |\n",
      "|  ES  | Alert    | -1.3  | 0.91  | -0.88 | -0.99 | 0.86  | -0.17 | 1.34  | -0.31  |\n",
      "|  ES  | Critical | -0.71 | -0.44 | -0.17 | 0.97  | 0.68  | -0.16 | -0.04 | 0.94   |\n",
      "|------+----------+-------+-------+-------+-------+-------+-------+-------+--------|\n"
     ]
    }
   ],
   "source": [
    "# Filter for rows with 'ES' in C00\n",
    "!csvgrep -c C00 -m ES ../data/raw/fromPandas.csv | head | csvlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|------+-------+-------+-------+-------+-------+-------+-------+-------+--------|\n",
      "|  C00 | D01   | C02   | D03   | D04   | A05   | A06   | B07   | A08   | C09    |\n",
      "|------+-------+-------+-------+-------+-------+-------+-------+-------+--------|\n",
      "|  PO  | Alert | 0.08  | -0.29 | 1.04  | 0.5   | -0.19 | 0.92  | -1.18 | 0.46   |\n",
      "|  PO  | Alert | 0.86  | 1.81  | 2.28  | 1.58  | 0.79  | 1.19  | 0.99  | -1.17  |\n",
      "|  AR  | Alert | -0.15 | 0.03  | -2.05 | -0.56 | -1.04 | 1.29  | 0.51  | -0.01  |\n",
      "|  PO  | Alert | -0.17 | -0.4  | -0.16 | 2.65  | -0.48 | 0.25  | -1.1  | 0.77   |\n",
      "|  AR  | Alert | -0.57 | -0.31 | -0.14 | -2.89 | 0.52  | 0.18  | -0.03 | 0.47   |\n",
      "|  AR  | Alert | -0.73 | 0.89  | -0.54 | -0.03 | 2.15  | 0.37  | 0.08  | 0.84   |\n",
      "|  AR  | Alert | 0.11  | -0.37 | -0.17 | -0.24 | -1.03 | 0.2   | -1.13 | 0.33   |\n",
      "|  AR  | Alert | 1.01  | 1.13  | 1.0   | 0.44  | 0.04  | -0.02 | 0.82  | -0.06  |\n",
      "|  PO  | Alert | 1.5   | 0.18  | -0.29 | -1.26 | 0.65  | 1.88  | 0.68  | 0.68   |\n",
      "|------+-------+-------+-------+-------+-------+-------+-------+-------+--------|\n"
     ]
    }
   ],
   "source": [
    "# Filter for rows with no 'Crit' in D01\n",
    "!csvgrep -ic D01 -m Crit ../data/raw/fromPandas.csv | head | csvlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## `csvsort`\n",
    "\n",
    "<br>\n",
    "\n",
    "```\n",
    "Options\n",
    "\n",
    "  -c COLUMNS, --columns COLUMNS\n",
    "                        A comma separated list of column indices or names to\n",
    "                        sort by. Defaults to all columns.\n",
    "  -r, --reverse         Sort in descending order.\n",
    "  --no-inference        Disable type inference when parsing the input.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|------+----------+-------+-------+-------+-------+-------+-------+-------+--------|\n",
      "|  C00 | D01      | C02   | D03   | D04   | A05   | A06   | B07   | A08   | C09    |\n",
      "|------+----------+-------+-------+-------+-------+-------+-------+-------+--------|\n",
      "|  AR  | Critical | -0.28 | 0.56  | 0.69  | 0.62  | -0.28 | -0.25 | 0.64  | -2.03  |\n",
      "|  AR  | Critical | 0.04  | -0.38 | -0.66 | -1.76 | -0.13 | 0.6   | -2.06 | 0.96   |\n",
      "|  AR  | Alert    | -0.15 | 0.03  | -2.05 | -0.56 | -1.04 | 1.29  | 0.51  | -0.01  |\n",
      "|  AR  | Alert    | -0.57 | -0.31 | -0.14 | -2.89 | 0.52  | 0.18  | -0.03 | 0.47   |\n",
      "|  AR  | Critical | -1.09 | -0.21 | 0.65  | 0.7   | 0.43  | -0.46 | 0.72  | -0.24  |\n",
      "|  AR  | Alert    | -0.73 | 0.89  | -0.54 | -0.03 | 2.15  | 0.37  | 0.08  | 0.84   |\n",
      "|  AR  | Alert    | 0.11  | -0.37 | -0.17 | -0.24 | -1.03 | 0.2   | -1.13 | 0.33   |\n",
      "|  AR  | Alert    | 1.01  | 1.13  | 1.0   | 0.44  | 0.04  | -0.02 | 0.82  | -0.06  |\n",
      "|  AR  | Critical | -0.06 | 0.26  | 0.47  | -1.73 | -1.34 | 1.59  | -1.01 | 0.94   |\n",
      "|------+----------+-------+-------+-------+-------+-------+-------+-------+--------|\n"
     ]
    }
   ],
   "source": [
    "# ascending\n",
    "!head -n 1000 ../data/raw/fromPandas.csv \\\n",
    "| csvsort -c C00 \\\n",
    "| head | csvlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|------+----------+------+-------+-------+-------+-------+-------+-------+-------|\n",
      "|  C00 | D01      | C02  | D03   | D04   | A05   | A06   | B07   | A08   | C09   |\n",
      "|------+----------+------+-------+-------+-------+-------+-------+-------+-------|\n",
      "|  AR  | Critical | 3.38 | -0.45 | -0.08 | 2.16  | 0.4   | -0.09 | 0.82  | -1.1  |\n",
      "|  PO  | Alert    | 2.97 | 0.52  | 1.93  | 0.41  | -1.27 | 0.88  | -1.39 | -1.5  |\n",
      "|  RU  | Alert    | 2.96 | 0.46  | -0.14 | -0.69 | 0.23  | 0.77  | 1.18  | 0.83  |\n",
      "|  PO  | Critical | 2.6  | 1.03  | -0.72 | -1.31 | -1.02 | -0.84 | -1.48 | -0.6  |\n",
      "|  PO  | Alert    | 2.58 | 0.1   | 1.24  | -0.26 | -0.53 | -1.0  | 0.2   | 1.04  |\n",
      "|  PO  | Critical | 2.54 | -0.07 | -0.24 | -0.56 | -1.85 | -0.2  | 0.48  | 1.89  |\n",
      "|  PO  | Critical | 2.52 | 0.49  | 0.78  | -1.57 | -1.08 | -1.02 | 0.77  | 0.21  |\n",
      "|  PO  | Critical | 2.41 | -0.19 | -0.6  | 0.56  | -0.91 | -0.71 | -1.75 | 2.32  |\n",
      "|  AR  | Critical | 2.41 | -1.22 | -0.06 | 1.06  | 0.23  | 0.34  | 1.02  | 0.09  |\n",
      "|------+----------+------+-------+-------+-------+-------+-------+-------+-------|\n"
     ]
    }
   ],
   "source": [
    "# descending\n",
    "!head -n 1000 ../data/raw/fromPandas.csv \\\n",
    "| csvsort -rc C02 \\\n",
    "| head | csvlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## `csvstat`\n",
    "\n",
    "- Outputs the statistical summary of all/particular columns\n",
    "- Default action is to provide a lot of information (you can choose either all or one.\n",
    "\n",
    "> - Tells you if there are nulls ina a column (will hog the memory - maybe run inside Docker?)\n",
    "- Gives you info on the dtypes\n",
    "- Frequency table for free!\n",
    "- !!!---painfully slow---!!! (I would crontab this to run overnight)\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "```\n",
    "Options\n",
    "\n",
    "  --max                 Only output max.\n",
    "  --min                 Only output min.\n",
    "  --sum                 Only output sum.\n",
    "  --mean                Only output mean.\n",
    "  --median              Only output median.\n",
    "  --stdev               Only output standard deviation.\n",
    "  --nulls               Only output whether column contains nulls.\n",
    "  --unique              Only output unique values.\n",
    "  --freq                Only output frequent values.\n",
    "  --len                 Only output max value length.\n",
    "  --count               Only output row count\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5. src_bytes\n",
      "\t<type 'int'>\n",
      "\tNulls: False\n",
      "\tMin: 0\n",
      "\tMax: 1379963888\n",
      "\tSum: 8986765238\n",
      "\tMean: 1834.62117523\n",
      "\tMedian: 520\n",
      "\tStandard Deviation: 941430.978396\n",
      "\tUnique values: 7195\n",
      "\t5 most frequent values:\n",
      "\t\t1032:\t2280245\n",
      "\t\t0:\t1152546\n",
      "\t\t520:\t527731\n",
      "\t\t105:\t73899\n",
      "\t\t147:\t27324\n",
      "  6. dst_bytes\n",
      "\t<type 'int'>\n",
      "\tNulls: False\n",
      "\tMin: 0\n",
      "\tMax: 1309937401\n",
      "\tSum: 5357035893\n",
      "\tMean: 1093.62281371\n",
      "\tMedian: 0\n",
      "\tStandard Deviation: 645012.267904\n",
      "\tUnique values: 21493\n",
      "\t5 most frequent values:\n",
      "\t\t0:\t4064854\n",
      "\t\t105:\t44713\n",
      "\t\t147:\t24910\n",
      "\t\t146:\t22536\n",
      "\t\t145:\t9500\n",
      "\n",
      "Row count: 4898431\n"
     ]
    }
   ],
   "source": [
    "!csvstat -c src_bytes,dst_bytes ../data/raw/kdd.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \"ATL\": 413851, \"ORD\": 375784, \"DFW\": 297345, \"DEN\": 240928, \"LAX\": 237597 }"
     ]
    }
   ],
   "source": [
    "# Returns top 5 by default\n",
    "!csvstat -c Origin --freq ../data/raw/flights.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## `csvstack`\n",
    "\n",
    "```\n",
    "Options\n",
    "\n",
    "  -g GROUPS, --groups GROUPS\n",
    "                        A comma-seperated list of values to add as \"grouping\n",
    "                        factors\", one for each CSV being stacked. These will\n",
    "                        be added to the stacked CSV as a new column. You may\n",
    "                        specify a name for the grouping column using the -n\n",
    "                        flag.\n",
    "  -n GROUP_NAME, --group-name GROUP_NAME\n",
    "                        A name for the grouping column, e.g. \"year\". Only used\n",
    "                        when also specifying -g.\n",
    "  --filenames           Use the filename of each input file as its grouping\n",
    "                        value. When specified, -g will be ignored.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create files (only one should have the header)\n",
    "!head ../data/raw/fromPandas.csv > ../data/raw/fromPandas_01.csv\n",
    "!tail ../data/raw/fromPandas.csv > ../data/raw/fromPandas_02.csv\n",
    "\n",
    "!csvstack ../data/raw/fromPandas_01.csv ../data/raw/fromPandas_02.csv | csvlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|------+----------+-------+-------+-------+-------+-------+-------+-------+--------|\n",
      "|  C00 | D01      | C02   | D03   | D04   | A05   | A06   | B07   | A08   | C09    |\n",
      "|------+----------+-------+-------+-------+-------+-------+-------+-------+--------|\n",
      "|  PO  | Alert    | 0.08  | -0.29 | 1.04  | 0.5   | -0.19 | 0.92  | -1.18 | 0.46   |\n",
      "|  PO  | Alert    | 0.86  | 1.81  | 2.28  | 1.58  | 0.79  | 1.19  | 0.99  | -1.17  |\n",
      "|  PO  | Critical | -0.04 | 0.52  | -0.52 | 0.34  | 2.09  | -0.6  | 0.85  | -1.14  |\n",
      "|  AR  | Critical | -0.28 | 0.56  | 0.69  | 0.62  | -0.28 | -0.25 | 0.64  | -2.03  |\n",
      "|  AR  | Critical | 0.04  | -0.38 | -0.66 | -1.76 | -0.13 | 0.6   | -2.06 | 0.96   |\n",
      "|  PO  | Critical | 0.77  | 1.48  | 0.16  | -0.59 | 0.94  | 0.48  | -0.32 | -0.55  |\n",
      "|  AR  | Alert    | -0.15 | 0.03  | -2.05 | -0.56 | -1.04 | 1.29  | 0.51  | -0.01  |\n",
      "|  PO  | Alert    | -0.17 | -0.4  | -0.16 | 2.65  | -0.48 | 0.25  | -1.1  | 0.77   |\n",
      "|  AR  | Alert    | -0.57 | -0.31 | -0.14 | -2.89 | 0.52  | 0.18  | -0.03 | 0.47   |\n",
      "|  AR  | Alert    | 0.48  | -1.43 | -0.49 | -0.39 | 0.21  | 0.34  | -0.39 | 2.09   |\n",
      "|  AR  | Alert    | -0.64 | -1.7  | -1.1  | -0.97 | 0.76  | 0.63  | -0.72 | -0.9   |\n",
      "|  AR  | Critical | 1.12  | 0.94  | 0.62  | 1.01  | -0.86 | 0.08  | 1.59  | 2.67   |\n",
      "|  AR  | Alert    | 1.15  | 0.9   | -1.02 | 0.85  | -1.62 | -1.31 | 2.09  | -0.03  |\n",
      "|  AR  | Alert    | 0.05  | 0.85  | -0.55 | -2.99 | 0.05  | 1.06  | -0.04 | 1.57   |\n",
      "|  PO  | Alert    | 1.15  | 0.6   | 1.14  | -0.49 | 0.26  | -0.9  | -0.43 | -0.54  |\n",
      "|  AR  | Alert    | 0.04  | 0.58  | -1.8  | 0.87  | 1.47  | -0.09 | -1.07 | 0.05   |\n",
      "|  AR  | Alert    | -0.2  | -0.25 | 0.89  | -0.08 | -1.58 | -0.74 | -0.84 | -0.17  |\n",
      "|  PO  | Critical | -0.18 | 2.15  | -1.52 | -0.86 | 0.23  | -0.77 | -2.11 | -0.19  |\n",
      "|------+----------+-------+-------+-------+-------+-------+-------+-------+--------|\n"
     ]
    }
   ],
   "source": [
    "# globbing allowed\n",
    "!csvstack ../data/raw/fromPandas_0* | csvlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-----------------------+-----+----------+-------+-------+-------+-------+-------+-------+-------+--------|\n",
      "|  contributing_dataset | C00 | D01      | C02   | D03   | D04   | A05   | A06   | B07   | A08   | C09    |\n",
      "|-----------------------+-----+----------+-------+-------+-------+-------+-------+-------+-------+--------|\n",
      "|  head                 | PO  | Alert    | 0.08  | -0.29 | 1.04  | 0.5   | -0.19 | 0.92  | -1.18 | 0.46   |\n",
      "|  head                 | PO  | Alert    | 0.86  | 1.81  | 2.28  | 1.58  | 0.79  | 1.19  | 0.99  | -1.17  |\n",
      "|  head                 | PO  | Critical | -0.04 | 0.52  | -0.52 | 0.34  | 2.09  | -0.6  | 0.85  | -1.14  |\n",
      "|  head                 | AR  | Critical | -0.28 | 0.56  | 0.69  | 0.62  | -0.28 | -0.25 | 0.64  | -2.03  |\n",
      "|  head                 | AR  | Critical | 0.04  | -0.38 | -0.66 | -1.76 | -0.13 | 0.6   | -2.06 | 0.96   |\n",
      "|  head                 | PO  | Critical | 0.77  | 1.48  | 0.16  | -0.59 | 0.94  | 0.48  | -0.32 | -0.55  |\n",
      "|  head                 | AR  | Alert    | -0.15 | 0.03  | -2.05 | -0.56 | -1.04 | 1.29  | 0.51  | -0.01  |\n",
      "|  head                 | PO  | Alert    | -0.17 | -0.4  | -0.16 | 2.65  | -0.48 | 0.25  | -1.1  | 0.77   |\n",
      "|  head                 | AR  | Alert    | -0.57 | -0.31 | -0.14 | -2.89 | 0.52  | 0.18  | -0.03 | 0.47   |\n",
      "|  tail                 | AR  | Alert    | 0.48  | -1.43 | -0.49 | -0.39 | 0.21  | 0.34  | -0.39 | 2.09   |\n",
      "|  tail                 | AR  | Alert    | -0.64 | -1.7  | -1.1  | -0.97 | 0.76  | 0.63  | -0.72 | -0.9   |\n",
      "|  tail                 | AR  | Critical | 1.12  | 0.94  | 0.62  | 1.01  | -0.86 | 0.08  | 1.59  | 2.67   |\n",
      "|  tail                 | AR  | Alert    | 1.15  | 0.9   | -1.02 | 0.85  | -1.62 | -1.31 | 2.09  | -0.03  |\n",
      "|  tail                 | AR  | Alert    | 0.05  | 0.85  | -0.55 | -2.99 | 0.05  | 1.06  | -0.04 | 1.57   |\n",
      "|  tail                 | PO  | Alert    | 1.15  | 0.6   | 1.14  | -0.49 | 0.26  | -0.9  | -0.43 | -0.54  |\n",
      "|  tail                 | AR  | Alert    | 0.04  | 0.58  | -1.8  | 0.87  | 1.47  | -0.09 | -1.07 | 0.05   |\n",
      "|  tail                 | AR  | Alert    | -0.2  | -0.25 | 0.89  | -0.08 | -1.58 | -0.74 | -0.84 | -0.17  |\n",
      "|  tail                 | PO  | Critical | -0.18 | 2.15  | -1.52 | -0.86 | 0.23  | -0.77 | -2.11 | -0.19  |\n",
      "|-----------------------+-----+----------+-------+-------+-------+-------+-------+-------+-------+--------|\n"
     ]
    }
   ],
   "source": [
    "!csvstack -g head,tail -n contributing_dataset ../data/raw/fromPandas_0* | csvlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--------------------+-----+----------+-------+-------+-------+-------+-------+-------+-------+--------|\n",
      "|  group             | C00 | D01      | C02   | D03   | D04   | A05   | A06   | B07   | A08   | C09    |\n",
      "|--------------------+-----+----------+-------+-------+-------+-------+-------+-------+-------+--------|\n",
      "|  fromPandas_01.csv | PO  | Alert    | 0.08  | -0.29 | 1.04  | 0.5   | -0.19 | 0.92  | -1.18 | 0.46   |\n",
      "|  fromPandas_01.csv | PO  | Alert    | 0.86  | 1.81  | 2.28  | 1.58  | 0.79  | 1.19  | 0.99  | -1.17  |\n",
      "|  fromPandas_01.csv | PO  | Critical | -0.04 | 0.52  | -0.52 | 0.34  | 2.09  | -0.6  | 0.85  | -1.14  |\n",
      "|  fromPandas_01.csv | AR  | Critical | -0.28 | 0.56  | 0.69  | 0.62  | -0.28 | -0.25 | 0.64  | -2.03  |\n",
      "|  fromPandas_01.csv | AR  | Critical | 0.04  | -0.38 | -0.66 | -1.76 | -0.13 | 0.6   | -2.06 | 0.96   |\n",
      "|  fromPandas_01.csv | PO  | Critical | 0.77  | 1.48  | 0.16  | -0.59 | 0.94  | 0.48  | -0.32 | -0.55  |\n",
      "|  fromPandas_01.csv | AR  | Alert    | -0.15 | 0.03  | -2.05 | -0.56 | -1.04 | 1.29  | 0.51  | -0.01  |\n",
      "|  fromPandas_01.csv | PO  | Alert    | -0.17 | -0.4  | -0.16 | 2.65  | -0.48 | 0.25  | -1.1  | 0.77   |\n",
      "|  fromPandas_01.csv | AR  | Alert    | -0.57 | -0.31 | -0.14 | -2.89 | 0.52  | 0.18  | -0.03 | 0.47   |\n",
      "|  fromPandas_02.csv | AR  | Alert    | 0.48  | -1.43 | -0.49 | -0.39 | 0.21  | 0.34  | -0.39 | 2.09   |\n",
      "|  fromPandas_02.csv | AR  | Alert    | -0.64 | -1.7  | -1.1  | -0.97 | 0.76  | 0.63  | -0.72 | -0.9   |\n",
      "|  fromPandas_02.csv | AR  | Critical | 1.12  | 0.94  | 0.62  | 1.01  | -0.86 | 0.08  | 1.59  | 2.67   |\n",
      "|  fromPandas_02.csv | AR  | Alert    | 1.15  | 0.9   | -1.02 | 0.85  | -1.62 | -1.31 | 2.09  | -0.03  |\n",
      "|  fromPandas_02.csv | AR  | Alert    | 0.05  | 0.85  | -0.55 | -2.99 | 0.05  | 1.06  | -0.04 | 1.57   |\n",
      "|  fromPandas_02.csv | PO  | Alert    | 1.15  | 0.6   | 1.14  | -0.49 | 0.26  | -0.9  | -0.43 | -0.54  |\n",
      "|  fromPandas_02.csv | AR  | Alert    | 0.04  | 0.58  | -1.8  | 0.87  | 1.47  | -0.09 | -1.07 | 0.05   |\n",
      "|  fromPandas_02.csv | AR  | Alert    | -0.2  | -0.25 | 0.89  | -0.08 | -1.58 | -0.74 | -0.84 | -0.17  |\n",
      "|  fromPandas_02.csv | PO  | Critical | -0.18 | 2.15  | -1.52 | -0.86 | 0.23  | -0.77 | -2.11 | -0.19  |\n",
      "|--------------------+-----+----------+-------+-------+-------+-------+-------+-------+-------+--------|\n"
     ]
    }
   ],
   "source": [
    "!csvstack --filenames ../data/raw/fromPandas_0* | csvlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## `csvsql`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generate SQL CREATE TABLE statements for one or more CSV files (**very useful!**)\n",
    "    - Execute these statements directly on a database\n",
    "- Execute one or more SQL queries.\n",
    "\n",
    "\n",
    "```\n",
    "OPTIONS\n",
    "\n",
    "-i {access,sybase,sqlite,informix,firebird,mysql,oracle,maxdb,postgresql,mssql}, --dialect {access,sybase,sqlite,informix,firebird,mysql,oracle,maxdb,postgresql,mssql}\n",
    "                        Dialect of SQL to generate. Only valid when --db is\n",
    "                        not specified.\n",
    "  --db CONNECTION_STRING\n",
    "                        If present, a sqlalchemy connection string to use to\n",
    "                        directly execute generated SQL on a database.\n",
    "  --query QUERY         Execute one or more SQL queries delimited by \";\" and\n",
    "                        output the result of the last query as CSV.\n",
    "  --insert              In addition to creating the table, also insert the\n",
    "                        data into the table. Only valid when --db is\n",
    "                        specified.\n",
    "  --tables TABLE_NAMES  Specify one or more names for the tables to be\n",
    "                        created. If omitted, the filename (minus extension) or\n",
    "                        \"stdin\" will be used.\n",
    "  --no-constraints      Generate a schema without length limits or null\n",
    "                        checks. Useful when sampling big tables.\n",
    "  --no-create           Skip creating a table. Only valid when --insert is\n",
    "                        specified.\n",
    "  --blanks              Do not coerce empty strings to NULL values.\n",
    "  --no-inference        Disable type inference when parsing the input.\n",
    "  --db-schema DB_SCHEMA\n",
    "                        Optional name of database schema to create table(s)\n",
    "                        in.\n",
    "        \n",
    "```        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"fromPandas_01\" (\n",
      "\t\"C00\" VARCHAR(2) NOT NULL, \n",
      "\t\"D01\" VARCHAR(8) NOT NULL, \n",
      "\t\"C02\" FLOAT NOT NULL, \n",
      "\t\"D03\" FLOAT NOT NULL, \n",
      "\t\"D04\" FLOAT NOT NULL, \n",
      "\t\"A05\" FLOAT NOT NULL, \n",
      "\t\"A06\" FLOAT NOT NULL, \n",
      "\t\"B07\" FLOAT NOT NULL, \n",
      "\t\"A08\" FLOAT NOT NULL, \n",
      "\t\"C09\" FLOAT NOT NULL\n",
      ");\n"
     ]
    }
   ],
   "source": [
    "!csvsql -i sqlite ../data/raw/fromPandas_01.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE stdin (\n",
      "\t\"Year\" INTEGER NOT NULL, \n",
      "\t\"Month\" INTEGER NOT NULL, \n",
      "\t\"DayofMonth\" INTEGER NOT NULL, \n",
      "\t\"DayOfWeek\" INTEGER NOT NULL, \n",
      "\t\"DepTime\" INTEGER, \n",
      "\t\"CRSDepTime\" INTEGER NOT NULL, \n",
      "\t\"ArrTime\" INTEGER, \n",
      "\t\"CRSArrTime\" INTEGER NOT NULL, \n",
      "\t\"UniqueCarrier\" VARCHAR(2) NOT NULL, \n",
      "\t\"FlightNum\" INTEGER NOT NULL, \n",
      "\t\"TailNum\" VARCHAR(6) NOT NULL, \n",
      "\t\"ActualElapsedTime\" INTEGER, \n",
      "\t\"CRSElapsedTime\" INTEGER NOT NULL, \n",
      "\t\"AirTime\" INTEGER, \n",
      "\t\"ArrDelay\" INTEGER, \n",
      "\t\"DepDelay\" INTEGER, \n",
      "\t\"Origin\" VARCHAR(3) NOT NULL, \n",
      "\t\"Dest\" VARCHAR(3) NOT NULL, \n",
      "\t\"Distance\" INTEGER NOT NULL, \n",
      "\t\"TaxiIn\" INTEGER NOT NULL, \n",
      "\t\"TaxiOut\" INTEGER NOT NULL, \n",
      "\t\"Cancelled\" INTEGER NOT NULL, \n",
      "\t\"CancellationCode\" VARCHAR(4), \n",
      "\t\"Diverted\" INTEGER NOT NULL, \n",
      "\t\"CarrierDelay\" INTEGER NOT NULL, \n",
      "\t\"WeatherDelay\" INTEGER NOT NULL, \n",
      "\t\"NASDelay\" INTEGER NOT NULL, \n",
      "\t\"SecurityDelay\" INTEGER NOT NULL, \n",
      "\t\"LateAircraftDelay\" INTEGER NOT NULL\n",
      ");\n"
     ]
    }
   ],
   "source": [
    "!head -n 10000 ../data/raw/flights.csv | csvsql -i postgresql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Killed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!csvsql --query \"\"\"SELECT distinct(interaction_type), count(*) \\\n",
    "                   FROM kdd \\\n",
    "                   WHERE src_bytes > 1000 \\\n",
    "                   GROUP BY 1 \\\n",
    "                   ORDER BY 2 DESC\"\"\" ../data/raw/kdd.csv | head | csvlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a table and import data from the CSV directly into Postgres:\n",
    "# to be tested\n",
    "!createdb test\n",
    "!csvsql --db postgresql:///test --table fy09 --insert examples/realdata/FY09_EDU_Recipients_by_State.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create tables for an entire folder of CSVs and import data from those files directly into Postgres:\n",
    "# to be tested\n",
    "!createdb test\n",
    "!csvsql --db postgresql:///test --insert examples/*.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
