{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNU Coreutils\n",
    "\n",
    "---\n",
    "\n",
    "These constitute one of most useful of all [GNU Packages](https://en.wikipedia.org/wiki/List_of_GNU_packages) that are a intergral part of the daily work of millions of programmers/scientists. <br>(Other well known packages include `grep`, `screen`, `gzip`, `tar`, `time` etc. Oh, and the `R` programming language.)\n",
    "\n",
    "> \"_The GNU Core Utilities are the basic file, shell and **text manipulation** utilities of the GNU operating system.These are the core utilities which are expected to **exist on every OS**._\"\n",
    "\n",
    "Examples include\n",
    "\n",
    "|Manipulate|Utils\n",
    "|---|---|\n",
    "|files | `chgrp, chown, chmod, cp, dd, df, dir, du, ln, ls, mkdir, mkfifo, mknod, mv, rm` etc.\n",
    "|text | `cat, cksum, head, tail, md5sum, nl, od, pr, tsort, join, wc, tac, paste` etc.\n",
    "|shell | `basename, chroot, date, dirname, echo, env, groups, hostname, nice, nohup, printf, sleep` etc.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Getting Help\n",
    "\n",
    "Documentation is built-in, so whenever you can't remember something, look it up using \n",
    "\n",
    "```bash\n",
    "COMMAND --help\n",
    "# or\n",
    "man COMMAND\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Know your system\n",
    "\n",
    "```bash\n",
    "# -------------------------------------------------------------------\n",
    "# Kernel Info \n",
    "\n",
    "uname -a # all \n",
    "uname -r # exact\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Linux Version\n",
    "\n",
    "lsb_release -a    # all\n",
    "lsb_release -r    # exact\n",
    "lsb_release -a -u # for derived distros like elementary\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# HDD Partition Info\n",
    "\n",
    "fdisk -l \n",
    "lsblk -o NAME,SIZE # human readable tree\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# LOCALE\n",
    "\n",
    "# List what locales currently defined for the current user \n",
    "locale\n",
    "\n",
    "# if needed, generate missing locale and reconfigure\n",
    "sudo locale-gen \"en_US.UTF-8\"\n",
    "sudo dpkg-reconfigure locales\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# ENVIRONMENT VARIABLES\n",
    "\n",
    "env\n",
    "# this will list all active variables\n",
    "\n",
    "EXPORT ENV_VAR=val\n",
    "# will add a new variable to the list\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# PATH\n",
    "\n",
    "echo $PATH\n",
    "# will list the programs on the path\n",
    "\n",
    "# add optional binary to the end of the path\n",
    "PATH=$PATH:~/opt/bin\n",
    "\n",
    "# add something ot the beginning\n",
    "PATH=~/opt/bin:$PATH\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# The very basics\n",
    "\n",
    "$ mkdir d && cd d\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Shortcuts\n",
    "\n",
    "| | |\n",
    "| --- | --- |\n",
    "| `Ctrl + U` | Clears the line from the cursor point back to the beginning. |\n",
    "| `Ctrl + A` | Moves the cursor to the beginning of the line. |\n",
    "| `Ctrl + E` | Moves the cursor to the end of the line. |\n",
    "| `Ctrl + R` | Allows you to search through the previous commands |\n",
    "\n",
    "---\n",
    "\n",
    "## Why Coreutils?\n",
    "\n",
    "\n",
    "The basic tenet of UNIX philosophy is to \n",
    "\n",
    ">  _\"create programs (or processes) that do one thing, and do that one thing well.\"_ <br><br>\n",
    "It is a philosophy demanding careful thought about interfaces and ways of _joining these smaller (hopefully more simple) processes together to create useful results_. \n",
    "\n",
    "Normally text data flows between these interfaces. More advanced text processing tools and languages (like perl, python, and ruby) have been developed, which though very capable in their own right, **are not always available, especially in a production environment.**\n",
    "\n",
    "These coreutils therefore become an indespensable tool in the data scientist's toolbox if he wants to build systems that work beyond his laptop.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Common Util Options\n",
    "\n",
    "- can appear in any order (recommended: `options` before `operands`)\n",
    "- options can be long (begin with `--`) or abbreviated (begin wiht `-`)\n",
    "- available to all programs (eg. `--help`, `--version`) \n",
    "\n",
    "> _Nearly every command invocation yields an integral **exit status** that can be used to change how other commands work. For the vast majority of commands, an exit status of **zero indicates success, nonzero indicates failure**._\n",
    "\n",
    "Alright, enough talk, let's dive in. Like most things on the internet these days, our story begins with a ... \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## cat, tac\n",
    "\n",
    "- Copies file/stdin to file/stdout (careful with large files!!)\n",
    "- Useful in piping text to other programns, and to write output to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: cat [OPTION]... [FILE]...\n",
      "Concatenate FILE(s) to standard output.\n",
      "\n",
      "With no FILE, or when FILE is -, read standard input.\n",
      "\n",
      "  -A, --show-all           equivalent to -vET\n",
      "  -b, --number-nonblank    number nonempty output lines, overrides -n\n",
      "  -e                       equivalent to -vE\n",
      "  -E, --show-ends          display $ at end of each line\n",
      "  -n, --number             number all output lines\n",
      "  -s, --squeeze-blank      suppress repeated empty output lines\n",
      "  -t                       equivalent to -vT\n",
      "  -T, --show-tabs          display TAB characters as ^I\n",
      "  -u                       (ignored)\n",
      "  -v, --show-nonprinting   use ^ and M- notation, except for LFD and TAB\n",
      "      --help     display this help and exit\n",
      "      --version  output version information and exit\n",
      "\n",
      "Examples:\n",
      "  cat f - g  Output f's contents, then standard input, then g's contents.\n",
      "  cat        Copy standard input to standard output.\n",
      "\n",
      "GNU coreutils online help: <http://www.gnu.org/software/coreutils/>\n",
      "Full documentation at: <http://www.gnu.org/software/coreutils/cat>\n",
      "or available locally via: info '(coreutils) cat invocation'\n"
     ]
    }
   ],
   "source": [
    "!cat --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing f01.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile f01.txt\n",
    "1 2 3\n",
    "4 5 6\n",
    "\n",
    "7 8 9\n",
    "\n",
    "\n",
    "10 11 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\t1 2 3\n",
      "     2\t4 5 6\n",
      "     3\t\n",
      "     4\t7 8 9\n",
      "     5\t\n",
      "     6\t\n",
      "     7\t10 11 12"
     ]
    }
   ],
   "source": [
    "# create an index\n",
    "!cat -n f01.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\t1 2 3\n",
      "     2\t4 5 6\n",
      "\n",
      "     3\t7 8 9\n",
      "\n",
      "\n",
      "     4\t10 11 12"
     ]
    }
   ],
   "source": [
    "# create index for nonmissing\n",
    "!cat -b f01.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\t1 2 3\n",
      "     2\t4 5 6\n",
      "\n",
      "     3\t7 8 9\n",
      "\n",
      "     4\t10 11 12"
     ]
    }
   ],
   "source": [
    "# squeeze multiple blank lines to 1\n",
    "!cat -bs f01.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 11 12\n",
      "\n",
      "7 8 9\n",
      "\n",
      "4 5 6\n",
      "1 2 3\n"
     ]
    }
   ],
   "source": [
    "# reverse rows\n",
    "!tac f01.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cat\n",
    "\n",
    "** To append Structured Files **\n",
    "\n",
    "\n",
    "- Concatenating files (same number of columns in the same order, no headers)\n",
    "\n",
    "```bash\n",
    "cat f1.csv f2.csv f3.csv > f1_f2_f3.csv\n",
    "```\n",
    "- Appending a file to an existing file using the `>>` operator, removing headers from subsequent files\n",
    "\n",
    "```bash\n",
    "cat f1.csv > concatenated.csv\n",
    "cat f2.csv | sed \"1 d\" >> concatenated.csv\n",
    "cat f3.csv | sed \"1 d\" >> concatenated.csv\n",
    "```\n",
    "\n",
    "- Create a new file with the last few records of an existing file\n",
    "\n",
    "```bash\n",
    "head -n 1 foo.csv > new_foo.csv\n",
    "tail -n 9 foo.csv >> new_foo.csv\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,11\n",
      "12,13\n",
      "14,15\n",
      "16,17\n",
      "18,19\n",
      "20,21\n",
      "80,81\n",
      "82,83\n",
      "84,85\n",
      "86,87\n",
      "88,89\n"
     ]
    }
   ],
   "source": [
    "# row binding\n",
    "!seq 10 21 | paste -d, - - > f01.txt\n",
    "!seq 80 89 | paste -d, - - > f02.txt`\n",
    "!cat f01.txt f02.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## nl\n",
    "\n",
    "- add line numbers (generate and *index* like in `pandas`)\n",
    "- see options with `nl --help`\n",
    "  - `-s` to specify delimiter\n",
    "  - `-b` to use regexs \n",
    "\n",
    "```bash\n",
    "# for a csv\n",
    "cat flights.csv | nl -s, | tail\n",
    "\n",
    "# for a pipe-delimited file\n",
    "cat sample_2.txt | nl -s'|' | tail\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## head, tail\n",
    "\n",
    "- display the first or last `n` rows (`n=10` by default) of a file (or many files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year,Month,DayofMonth,DayOfWeek,DepTime,CRSDepTime,ArrTime,CRSArrTime,UniqueCarrier,FlightNum,TailNum,ActualElapsedTime,CRSElapsedTime,AirTime,ArrDelay,DepDelay,Origin,Dest,Distance,TaxiIn,TaxiOut,Cancelled,CancellationCode,Diverted,CarrierDelay,WeatherDelay,NASDelay,SecurityDelay,LateAircraftDelay\n",
      "2007,1,1,1,1232,1225,1341,1340,WN,2891,N351,69,75,54,1,7,SMF,ONT,389,4,11,0,,0,0,0,0,0,0\n",
      "2007,1,1,1,1918,1905,2043,2035,WN,462,N370,85,90,74,8,13,SMF,PDX,479,5,6,0,,0,0,0,0,0,0\n",
      "2007,1,1,1,2206,2130,2334,2300,WN,1229,N685,88,90,73,34,36,SMF,PDX,479,6,9,0,,0,3,0,0,0,31\n",
      "2007,1,1,1,1230,1200,1356,1330,WN,1355,N364,86,90,75,26,30,SMF,PDX,479,3,8,0,,0,23,0,0,0,3\n",
      "2007,1,1,1,831,830,957,1000,WN,2278,N480,86,90,74,-3,1,SMF,PDX,479,3,9,0,,0,0,0,0,0,0\n",
      "2007,1,1,1,1430,1420,1553,1550,WN,2386,N611SW,83,90,74,3,10,SMF,PDX,479,2,7,0,,0,0,0,0,0,0\n",
      "2007,1,1,1,1936,1840,2217,2130,WN,409,N482,101,110,89,47,56,SMF,PHX,647,5,7,0,,0,46,0,0,0,1\n",
      "2007,1,1,1,944,935,1223,1225,WN,1131,N749SW,99,110,86,-2,9,SMF,PHX,647,4,9,0,,0,0,0,0,0,0\n",
      "2007,1,1,1,1537,1450,1819,1735,WN,1212,N451,102,105,90,44,47,SMF,PHX,647,5,7,0,,0,20,0,0,0,24\n"
     ]
    }
   ],
   "source": [
    "!head flights.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year,Month,DayofMonth,DayOfWeek,DepTime,CRSDepTime,ArrTime,CRSArrTime,UniqueCarrier,FlightNum,TailNum,ActualElapsedTime,CRSElapsedTime,AirTime,ArrDelay,DepDelay,Origin,Dest,Distance,TaxiIn,TaxiOut,Cancelled,CancellationCode,Diverted,CarrierDelay,WeatherDelay,NASDelay,SecurityDelay,LateAircraftDelay\n",
      "2007,1,1,1,1232,1225,1341,1340,WN,2891,N351,69,75,54,1,7,SMF,ONT,389,4,11,0,,0,0,0,0,0,0\n",
      "2007,1,1,1,1918,1905,2043,2035,WN,462,N370,85,90,74,8,13,SMF,PDX,479,5,6,0,,0,0,0,0,0,0\n"
     ]
    }
   ],
   "source": [
    "!head -n 3 flights.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007,12,15,6,1024,1025,1750,1735,DL,61,N623DL,266,250,233,15,-1,LAX,ATL,1946,14,19,0,,0,0,0,15,0,0\n",
      "2007,12,15,6,1353,1315,1658,1622,DL,62,N970DL,125,127,100,36,38,DFW,ATL,732,11,14,0,,0,0,0,0,0,36\n",
      "2007,12,15,6,1824,1800,2001,1928,DL,63,N628DL,97,88,61,33,24,ATL,MCO,403,10,26,0,,0,24,0,9,0,0\n"
     ]
    }
   ],
   "source": [
    "!tail -n 3 flights.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## split\n",
    "\n",
    "- creates output files containing consecutive or interleaved sections (1000 lines by default) of input\n",
    "- files created are saved in the cd, named as PREFIXSUFFIX\n",
    "    - PREFIX is supplied with the call\n",
    "    - SUFFIX length is supplied (defaults to 2, so generates codes like `xaa, xab, xac` ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: split [OPTION]... [FILE [PREFIX]]\n",
      "Output pieces of FILE to PREFIXaa, PREFIXab, ...;\n",
      "default size is 1000 lines, and default PREFIX is 'x'.\n",
      "\n",
      "With no FILE, or when FILE is -, read standard input.\n",
      "\n",
      "Mandatory arguments to long options are mandatory for short options too.\n",
      "  -a, --suffix-length=N   generate suffixes of length N (default 2)\n",
      "      --additional-suffix=SUFFIX  append an additional SUFFIX to file names\n",
      "  -b, --bytes=SIZE        put SIZE bytes per output file\n",
      "  -C, --line-bytes=SIZE   put at most SIZE bytes of records per output file\n",
      "  -d                      use numeric suffixes starting at 0, not alphabetic\n",
      "      --numeric-suffixes[=FROM]  same as -d, but allow setting the start value\n",
      "  -e, --elide-empty-files  do not generate empty output files with '-n'\n",
      "      --filter=COMMAND    write to shell COMMAND; file name is $FILE\n",
      "  -l, --lines=NUMBER      put NUMBER lines/records per output file\n",
      "  -n, --number=CHUNKS     generate CHUNKS output files; see explanation below\n",
      "  -t, --separator=SEP     use SEP instead of newline as the record separator;\n",
      "                            '\\0' (zero) specifies the NUL character\n",
      "  -u, --unbuffered        immediately copy input to output with '-n r/...'\n",
      "      --verbose           print a diagnostic just before each\n",
      "                            output file is opened\n",
      "      --help     display this help and exit\n",
      "      --version  output version information and exit\n",
      "\n",
      "The SIZE argument is an integer and optional unit (example: 10K is 10*1024).\n",
      "Units are K,M,G,T,P,E,Z,Y (powers of 1024) or KB,MB,... (powers of 1000).\n",
      "\n",
      "CHUNKS may be:\n",
      "  N       split into N files based on size of input\n",
      "  K/N     output Kth of N to stdout\n",
      "  l/N     split into N files without splitting lines/records\n",
      "  l/K/N   output Kth of N to stdout without splitting lines/records\n",
      "  r/N     like 'l' but use round robin distribution\n",
      "  r/K/N   likewise but only output Kth of N to stdout\n",
      "\n",
      "GNU coreutils online help: <http://www.gnu.org/software/coreutils/>\n",
      "Full documentation at: <http://www.gnu.org/software/coreutils/split>\n",
      "or available locally via: info '(coreutils) split invocation'\n"
     ]
    }
   ],
   "source": [
    "!split --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!tail -n 1000 flights.csv > flights_1k.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!split -n 3 flights_1k.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xaa\n",
      "xab\n",
      "xac\n"
     ]
    }
   ],
   "source": [
    "ls | grep 'xa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# provide prefix\n",
    "!split -n 3 flights_1k.csv flights_1k_split_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flights_1k_split_aa\n",
      "flights_1k_split_ab\n",
      "flights_1k_split_ac\n"
     ]
    }
   ],
   "source": [
    "ls | grep 'split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# provide longer suffix if there are going to be many parts\n",
    "! split -n 5 -a 4 flights_1k.csv Part_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part_aaaa\n",
      "Part_aaab\n",
      "Part_aaac\n",
      "Part_aaad\n",
      "Part_aaae\n"
     ]
    }
   ],
   "source": [
    "ls | grep '^Part_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cleaning up\n",
    "!ls | grep '_split_' | xargs rm\n",
    "!ls | grep 'Part_' | xargs rm \n",
    "!ls | grep 'xa' | xargs rm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### csplit\n",
    "\n",
    "- for _copy-till-you-see-this_ kind of splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: csplit [OPTION]... FILE PATTERN...\n",
      "Output pieces of FILE separated by PATTERN(s) to files 'xx00', 'xx01', ...,\n",
      "and output byte counts of each piece to standard output.\n",
      "\n",
      "Read standard input if FILE is -\n",
      "\n",
      "Mandatory arguments to long options are mandatory for short options too.\n",
      "  -b, --suffix-format=FORMAT  use sprintf FORMAT instead of %02d\n",
      "  -f, --prefix=PREFIX        use PREFIX instead of 'xx'\n",
      "  -k, --keep-files           do not remove output files on errors\n",
      "      --suppress-matched     suppress the lines matching PATTERN\n",
      "  -n, --digits=DIGITS        use specified number of digits instead of 2\n",
      "  -s, --quiet, --silent      do not print counts of output file sizes\n",
      "  -z, --elide-empty-files    remove empty output files\n",
      "      --help     display this help and exit\n",
      "      --version  output version information and exit\n",
      "\n",
      "Each PATTERN may be:\n",
      "  INTEGER            copy up to but not including specified line number\n",
      "  /REGEXP/[OFFSET]   copy up to but not including a matching line\n",
      "  %REGEXP%[OFFSET]   skip to, but not including a matching line\n",
      "  {INTEGER}          repeat the previous pattern specified number of times\n",
      "  {*}                repeat the previous pattern as many times as possible\n",
      "\n",
      "A line OFFSET is a required '+' or '-' followed by a positive integer.\n",
      "\n",
      "GNU coreutils online help: <http://www.gnu.org/software/coreutils/>\n",
      "Full documentation at: <http://www.gnu.org/software/coreutils/csplit>\n",
      "or available locally via: info '(coreutils) csplit invocation'\n"
     ]
    }
   ],
   "source": [
    "!csplit --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## wc\n",
    "\n",
    "- counts the Number of bytes, characters, whitespace-separated words, and newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: wc [OPTION]... [FILE]...\n",
      "  or:  wc [OPTION]... --files0-from=F\n",
      "Print newline, word, and byte counts for each FILE, and a total line if\n",
      "more than one FILE is specified.  A word is a non-zero-length sequence of\n",
      "characters delimited by white space.\n",
      "\n",
      "With no FILE, or when FILE is -, read standard input.\n",
      "\n",
      "The options below may be used to select which counts are printed, always in\n",
      "the following order: newline, word, character, byte, maximum line length.\n",
      "  -c, --bytes            print the byte counts\n",
      "  -m, --chars            print the character counts\n",
      "  -l, --lines            print the newline counts\n",
      "      --files0-from=F    read input from the files specified by\n",
      "                           NUL-terminated names in file F;\n",
      "                           If F is - then read names from standard input\n",
      "  -L, --max-line-length  print the maximum display width\n",
      "  -w, --words            print the word counts\n",
      "      --help     display this help and exit\n",
      "      --version  output version information and exit\n",
      "\n",
      "GNU coreutils online help: <http://www.gnu.org/software/coreutils/>\n",
      "Full documentation at: <http://www.gnu.org/software/coreutils/wc>\n",
      "or available locally via: info '(coreutils) wc invocation'\n"
     ]
    }
   ],
   "source": [
    "!wc --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   7453216 flights.csv\n",
      "      1000 flights_1k.csv\n",
      "        27 get-csvs.sh\n",
      "        42 kddcup-names\n",
      "   4898431 kddcup.data\n",
      "  12352716 total\n"
     ]
    }
   ],
   "source": [
    "# count and filename\n",
    "!ls | xargs wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cut\n",
    "\n",
    "- select columns by position (comma separated list or hyphenated ranges)\n",
    "\n",
    "\n",
    "```bash\n",
    "OPTIONS\n",
    "\n",
    "-d, --delimiter=DELIM   use DELIM instead of TAB for field delimiter\n",
    "-f, --fields=LIST       select only these fields\n",
    "-s, --only-delimited    do not print lines not containing delimiters\n",
    "    --output-delimiter=STRING  use STRING as the output delimiter\n",
    "```        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,tcp,http,SF,215,45076,normal.\n",
      "0,tcp,http,SF,162,4528,normal.\n",
      "0,tcp,http,SF,236,1228,normal.\n",
      "0,tcp,http,SF,233,2032,normal.\n",
      "0,tcp,http,SF,239,486,normal.\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 kddcup.data | cut -d, -f1-6,42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UniqueCarrier,FlightNum,ArrDelay,DepDelay,Origin,Dest\n",
      "WN,2891,1,7,SMF,ONT\n",
      "WN,462,8,13,SMF,PDX\n",
      "WN,1229,34,36,SMF,PDX\n",
      "WN,1355,26,30,SMF,PDX\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 flights.csv | cut -d, -f9-10,15-18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## sort\n",
    "\n",
    "`sort` is quite versatile, and can be used to sort, sort & merge, randomize, and, deduplicate files.\n",
    "\n",
    "\n",
    "- Useful `sort` options <br>\n",
    "    - case insensitive with `-f`\n",
    "    - numbers with `-n`\n",
    "    - descending order with `-r`\n",
    "    - if lines have leading blanks `-b`\n",
    "    - sort by values in column 5 .... `-k5` (use `-t` for delimiter here)\n",
    "    - sort in random order with `-R`\n",
    "    - merge (sorted) multiple files with `-m`\n",
    "    - remove dups with `-u`\n",
    "    \n",
    "> Note <br> when using `-k` the syntax is `-km,n` where `m` is the starting key and `n` is the ending key. <br> If the sorting is on the 5th field alone (for ex.), we speciy `-k5,5`  <br><br> Environment variables such as LC_ALL, LC_COLLATE, or LANG can affect the output of sort and other commands. \n",
    "\n",
    "**Example**<br> To sort a csv file numerically on the 2nd field in reverse order we'd use\n",
    "\n",
    "```bash\n",
    "sort -t\",\" -k2nr,2 file\n",
    "```\n",
    "\n",
    "More examples [here](https://www.gnu.org/software/coreutils/manual/coreutils.html#Operating-on-sorted-files)\n",
    "\n",
    "### Sorting Large Files\n",
    "\n",
    "> _The sort that you find on Linux comes from the coreutils package and implements an External R-Way merge. It splits up the data into chunks that it can handle in memory, stores them on disc and then merges them. The chunks are done in parallel, if the machine has the processors for that. So if there was to be a limit, it is the free disc space that sort can use to store the temporary files it has to merge, combined with the result._\n",
    "[source](https://unix.stackexchange.com/questions/279096/scalability-of-sort-u-for-gigantic-files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: sort [OPTION]... [FILE]...\n",
      "  or:  sort [OPTION]... --files0-from=F\n",
      "Write sorted concatenation of all FILE(s) to standard output.\n",
      "\n",
      "With no FILE, or when FILE is -, read standard input.\n",
      "\n",
      "Mandatory arguments to long options are mandatory for short options too.\n",
      "Ordering options:\n",
      "\n",
      "  -b, --ignore-leading-blanks  ignore leading blanks\n",
      "  -d, --dictionary-order      consider only blanks and alphanumeric characters\n",
      "  -f, --ignore-case           fold lower case to upper case characters\n",
      "  -g, --general-numeric-sort  compare according to general numerical value\n",
      "  -i, --ignore-nonprinting    consider only printable characters\n",
      "  -M, --month-sort            compare (unknown) < 'JAN' < ... < 'DEC'\n",
      "  -h, --human-numeric-sort    compare human readable numbers (e.g., 2K 1G)\n",
      "  -n, --numeric-sort          compare according to string numerical value\n",
      "  -R, --random-sort           shuffle, but group identical keys.  See shuf(1)\n",
      "      --random-source=FILE    get random bytes from FILE\n",
      "  -r, --reverse               reverse the result of comparisons\n",
      "      --sort=WORD             sort according to WORD:\n",
      "                                general-numeric -g, human-numeric -h, month -M,\n",
      "                                numeric -n, random -R, version -V\n",
      "  -V, --version-sort          natural sort of (version) numbers within text\n",
      "\n",
      "Other options:\n",
      "\n",
      "      --batch-size=NMERGE   merge at most NMERGE inputs at once;\n",
      "                            for more use temp files\n",
      "  -c, --check, --check=diagnose-first  check for sorted input; do not sort\n",
      "  -C, --check=quiet, --check=silent  like -c, but do not report first bad line\n",
      "      --compress-program=PROG  compress temporaries with PROG;\n",
      "                              decompress them with PROG -d\n",
      "      --debug               annotate the part of the line used to sort,\n",
      "                              and warn about questionable usage to stderr\n",
      "      --files0-from=F       read input from the files specified by\n",
      "                            NUL-terminated names in file F;\n",
      "                            If F is - then read names from standard input\n",
      "  -k, --key=KEYDEF          sort via a key; KEYDEF gives location and type\n",
      "  -m, --merge               merge already sorted files; do not sort\n",
      "  -o, --output=FILE         write result to FILE instead of standard output\n",
      "  -s, --stable              stabilize sort by disabling last-resort comparison\n",
      "  -S, --buffer-size=SIZE    use SIZE for main memory buffer\n",
      "  -t, --field-separator=SEP  use SEP instead of non-blank to blank transition\n",
      "  -T, --temporary-directory=DIR  use DIR for temporaries, not $TMPDIR or /tmp;\n",
      "                              multiple options specify multiple directories\n",
      "      --parallel=N          change the number of sorts run concurrently to N\n",
      "  -u, --unique              with -c, check for strict ordering;\n",
      "                              without -c, output only the first of an equal run\n",
      "  -z, --zero-terminated     line delimiter is NUL, not newline\n",
      "      --help     display this help and exit\n",
      "      --version  output version information and exit\n",
      "\n",
      "KEYDEF is F[.C][OPTS][,F[.C][OPTS]] for start and stop position, where F is a\n",
      "field number and C a character position in the field; both are origin 1, and\n",
      "the stop position defaults to the line's end.  If neither -t nor -b is in\n",
      "effect, characters in a field are counted from the beginning of the preceding\n",
      "whitespace.  OPTS is one or more single-letter ordering options [bdfgiMhnRrV],\n",
      "which override global ordering options for that key.  If no key is given, use\n",
      "the entire line as the key.  Use --debug to diagnose incorrect key usage.\n",
      "\n",
      "SIZE may be followed by the following multiplicative suffixes:\n",
      "% 1% of memory, b 1, K 1024 (default), and so on for M, G, T, P, E, Z, Y.\n",
      "\n",
      "*** WARNING ***\n",
      "The locale specified by the environment affects sort order.\n",
      "Set LC_ALL=C to get the traditional sort order that uses\n",
      "native byte values.\n",
      "\n",
      "GNU coreutils online help: <http://www.gnu.org/software/coreutils/>\n",
      "Full documentation at: <http://www.gnu.org/software/coreutils/sort>\n",
      "or available locally via: info '(coreutils) sort invocation'\n"
     ]
    }
   ],
   "source": [
    "!sort --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw------- 1 root root 709M Mar  4 01:00 kddcup.data\n",
      "-rw------- 1 root root 671M Mar  4 01:05 flights.csv\n",
      "-rw-r--r-- 1 root root  94K Mar  4 01:26 flights_1k.csv\n",
      "-rw-r--r-- 1 root root 1.3K Mar  4 01:13 kddcup-names\n",
      "-rw-r--r-- 1 root root 1.2K Mar  4 01:01 get-csvs.sh\n",
      "total 1.4G\n"
     ]
    }
   ],
   "source": [
    "# sort listing of all files in a directory by their size (human-readable)\n",
    "!ls -lh | sort -k5,5 -h -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58329,udp,domain_u,SF,42,44\n",
      "42908,tcp,private,RSTR,1,0\n",
      "42888,tcp,private,RSTR,1,0\n",
      "42862,tcp,private,RSTR,1,0\n",
      "42837,tcp,private,RSTR,1,0\n",
      "42804,tcp,private,RSTR,1,0\n",
      "42778,tcp,private,RSTR,1,0\n",
      "42746,tcp,echo,RSTR,1,0\n",
      "42723,tcp,private,RSTR,1,0\n",
      "42699,tcp,discard,RSTR,1,0\n",
      "cut: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "# top 10 durations in the kdd data\n",
    "# Note\n",
    "# sed '1d' removes the header\n",
    "# cut is for retaining the first few columns\n",
    "!cat kddcup.data | sed '1d' | sort -nr -k1,1 | cut -d, -f1-6 | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `sort` has a `-u` flag that removes duplicate rows so a sorted listing of unique rows is produced.<br><br> **Note** <br>The commands sort -u and sort | uniq are equivalent, but this equivalence does not extend to arbitrary sort options. For example, sort -n -u inspects only the value of the initial numeric string when checking for uniqueness, whereas sort -n | uniq inspects the entire line. \n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## `shuf`\n",
    "\n",
    "- useful for **permutations** and **random sampling**\n",
    "- with or without **replacement** (_bootstrapped_ samples, anyone?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: shuf [OPTION]... [FILE]\n",
      "  or:  shuf -e [OPTION]... [ARG]...\n",
      "  or:  shuf -i LO-HI [OPTION]...\n",
      "Write a random permutation of the input lines to standard output.\n",
      "\n",
      "With no FILE, or when FILE is -, read standard input.\n",
      "\n",
      "Mandatory arguments to long options are mandatory for short options too.\n",
      "  -e, --echo                treat each ARG as an input line\n",
      "  -i, --input-range=LO-HI   treat each number LO through HI as an input line\n",
      "  -n, --head-count=COUNT    output at most COUNT lines\n",
      "  -o, --output=FILE         write result to FILE instead of standard output\n",
      "      --random-source=FILE  get random bytes from FILE\n",
      "  -r, --repeat              output lines can be repeated\n",
      "  -z, --zero-terminated     line delimiter is NUL, not newline\n",
      "      --help     display this help and exit\n",
      "      --version  output version information and exit\n",
      "\n",
      "GNU coreutils online help: <http://www.gnu.org/software/coreutils/>\n",
      "Full documentation at: <http://www.gnu.org/software/coreutils/shuf>\n",
      "or available locally via: info '(coreutils) shuf invocation'\n"
     ]
    }
   ],
   "source": [
    "!shuf --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "9\n",
      "5\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# without replacement\n",
    "!shuf -i1-9 -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Simulate a coin flip (with replacement)\n",
    "!shuf -i0-1 -r -n 10  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,icmp,ecr_i,SF,1032,0\n",
      "0,icmp,ecr_i,SF,1032,0\n",
      "0,icmp,ecr_i,SF,1032,0\n",
      "0,icmp,ecr_i,SF,1032,0\n",
      "0,icmp,ecr_i,SF,1032,0\n"
     ]
    }
   ],
   "source": [
    "# random sample from a file\n",
    "!cat kddcup.data | cut -d, -f1-6 | sed '1d' | shuf -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## uniq\n",
    "\n",
    "- typically used to uniquely list lines from an input source\n",
    "- find/remove duplicate rows in a file\n",
    "- frequency tables\n",
    "\n",
    "\n",
    "```bash\n",
    "OPTIONS\n",
    "\n",
    "-u, --unique          only print unique lines\n",
    "-c, --count           prefix lines by the number of occurrences\n",
    "-d, --repeated        only print duplicate lines, one for each group\n",
    "\n",
    "-D                    print all duplicate lines\n",
    "    --all-repeated[=METHOD]  like -D, but allow separating groups with an empty line;\n",
    "                             METHOD={none(default),prepend,separate}\n",
    "```        \n",
    "\n",
    "> To operate properly, duplicate lines must be contiguously positioned in the input. \n",
    "<br> So, normally the **input** to the `uniq` command **is first sorted.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198175\n"
     ]
    }
   ],
   "source": [
    "# number of uniuqe rows for columns 1-6, 42 in the kdd data\n",
    "!cat kddcup.data | sed '1d' | cut -d, -f1-6,42 | sort | uniq -u | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRC,RSTO,0,0,normal.\n",
      "IRC,RSTR,1010,6365,normal.\n",
      "IRC,RSTR,4420,7766,normal.\n",
      "IRC,RSTR,62,116,normal.\n",
      "IRC,RSTR,73,16,normal.\n",
      "IRC,RSTR,76,18,normal.\n",
      "IRC,RSTR,77,18,normal.\n",
      "IRC,S1,0,0,normal.\n",
      "IRC,SF,66,17,normal.\n",
      "IRC,SF,66,18,normal.\n",
      "uniq: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "# these rows have duplicates\n",
    "!cat kddcup.data | sed '1d' | cut -d, -f3-6,42 | sort | uniq -d | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2807886 smurf.\n",
      "1072017 neptune.\n",
      " 972780 normal.\n",
      "  15892 satan.\n",
      "  12481 ipsweep.\n"
     ]
    }
   ],
   "source": [
    "# frequency table\n",
    "!cat kddcup.data | sed '1d' | cut -d, -f42 | sort | uniq -c | sort -nr | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   9658 WN,HOU,DAL\n",
      "   9631 WN,DAL,HOU\n",
      "   7496 WN,LAX,OAK\n",
      "   7467 WN,OAK,LAX\n",
      "   7339 HA,OGG,HNL\n",
      "sort: write failed: standard output: Broken pipe\n",
      "sort: write error\n"
     ]
    }
   ],
   "source": [
    "# most number of flights?\n",
    "!cat flights.csv | sed '1d' | cut -d, -f9,17-18 | sort | uniq -c | sort -nr | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comm\n",
    "\n",
    "- for comparing sorted files FILE1 and FILE2 line by line.\n",
    "- With no options, produce three-column output.  \n",
    "    - Column one contains lines unique to FILE1, \n",
    "    - column two contains lines unique to FILE2,\n",
    "    - and column three contains lines common to both files.\n",
    "\n",
    "```bash \n",
    "OPTIONS\n",
    "\n",
    "  -1              suppress column 1 (lines unique to FILE1)\n",
    "  -2              suppress column 2 (lines unique to FILE2)\n",
    "  -3              suppress column 3 (lines that appear in both files)\n",
    "  \n",
    "EXAMPLES\n",
    "\n",
    "comm -12 file1 file2  \n",
    "# Print only lines present in both file1 and file2.\n",
    "\n",
    "comm -3 file1 file2  \n",
    "# Print lines in file1 not in file2, and vice versa.    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pull a random sample of 10k rows\n",
    "!shuf -n 10000 kddcup.data | sort > kdd_10k.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keep the first 7.5k rows as the train set\n",
    "!head -n 7500 kdd_10k.csv | sort > kdd_10k_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keep the other 2.5k as the test set\n",
    "!comm -3 kdd_10k.csv kdd_10k_train.csv | sort > kdd_10k_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  10000 kdd_10k.csv\n",
      "   2500 kdd_10k_test.csv\n",
      "   7500 kdd_10k_train.csv\n",
      "  20000 total\n"
     ]
    }
   ],
   "source": [
    "# check no. of rows\n",
    "!ls | grep '_10k' | xargs wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# see if we made a mistake\n",
    "!comm -12 kdd_10k_train.csv kdd_10k_test.csv | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# delete created files\n",
    "!ls | grep '_10k' | xargs rm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## paste\n",
    "\n",
    "- naive, brute force long-to-wide!\n",
    "- concat files (column binding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: paste [OPTION]... [FILE]...\n",
      "Write lines consisting of the sequentially corresponding lines from\n",
      "each FILE, separated by TABs, to standard output.\n",
      "\n",
      "With no FILE, or when FILE is -, read standard input.\n",
      "\n",
      "Mandatory arguments to long options are mandatory for short options too.\n",
      "  -d, --delimiters=LIST   reuse characters from LIST instead of TABs\n",
      "  -s, --serial            paste one file at a time instead of in parallel\n",
      "  -z, --zero-terminated    line delimiter is NUL, not newline\n",
      "      --help     display this help and exit\n",
      "      --version  output version information and exit\n",
      "\n",
      "GNU coreutils online help: <http://www.gnu.org/software/coreutils/>\n",
      "Full documentation at: <http://www.gnu.org/software/coreutils/paste>\n",
      "or available locally via: info '(coreutils) paste invocation'\n"
     ]
    }
   ],
   "source": [
    "!paste --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54,58,50,44,6\n",
      "25,67,88,11,52\n",
      "94,75,7,77,83\n",
      "95,56,82,46,44\n",
      "2,58,28,18,90\n"
     ]
    }
   ],
   "source": [
    "# join consecutive lines into a csv\n",
    "!shuf -i0-99 -rn 25 | paste -d, - - - - - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,2:3,4:5,6\n",
      "7,8:9,10:11,12\n"
     ]
    }
   ],
   "source": [
    "# fold data any which way\n",
    "!seq 12 | paste -d, - - | paste -d':' - - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,11,80,81\n",
      "12,13,82,83\n",
      "14,15,84,85\n",
      "16,17,86,87\n",
      "18,19,88,89\n",
      "20,21,\n"
     ]
    }
   ],
   "source": [
    "# column binding!\n",
    "!seq 10 21 | paste -d, - - > f01.txt\n",
    "!seq 80 89 | paste -d, - - > f02.txt\n",
    "!paste -d, f01.txt f02.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,11,12,13,14,15,16,17,18,19,20,21\n",
      "80,81,82,83,84,85,86,87,88,89\n"
     ]
    }
   ],
   "source": [
    "!paste -d, -s f01.txt f02.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm f01.txt f02.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1446MB\n",
      "-rw------- 1 root root 703MB Mar  4 01:05 flights.csv\n",
      "-rw-r--r-- 1 root root   1MB Mar  4 01:26 flights_1k.csv\n",
      "-rw-r--r-- 1 root root   1MB Mar  4 01:01 get-csvs.sh\n",
      "-rw-r--r-- 1 root root   1MB Mar  4 01:13 kddcup-names\n",
      "-rw------- 1 root root 743MB Mar  4 01:00 kddcup.data\n"
     ]
    }
   ],
   "source": [
    "ls -lh --block-size=MB ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [numfmt](https://www.gnu.org/software/coreutils/manual/html_node/numfmt-invocation.html#numfmt-invocation)\n",
    "\n",
    "- numfmt reads numbers in various representations and reformats them as requested\n",
    "-  numfmt can optionally extract numbers from specific columns, maintaining proper line padding and alignment.\n",
    "\n",
    "## Formatting floating point numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.3224                  20.9600  9.9800   7.3424\n",
      "43.38017000000000000000  52.4900  35.8600  7.5202\n",
      "6.60331000000000000000   7.9900   5.2100   1.3934\n",
      "24.78512000000000000000  29.9900  12.2300  12.5552\n",
      "12.38843000000000000000  14.9900  6.3400   6.0485\n",
      ".94340000000000000000    1.0000   0.4800   0.4634\n",
      "2.22314000000000000000   2.6900   0.9400   1.2832\n",
      "10.70248000000000000000  12.9500  5.6000   5.1025\n",
      "3.29752000000000000000   3.9900   0.9300   2.3676\n"
     ]
    }
   ],
   "source": [
    "!head Sales.txt  | sed '1d' | cut -d'|' -f12-15 | tr ',' '.' | xargs -d'|' numfmt --format=\"%0.4f\" | xargs -n4 | tr ' ' ',' | xsv table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Looping over files in Bash\n",
    "\n",
    "```bash\n",
    "for f in *; \n",
    "do  \n",
    "# do something, for example\n",
    "# wc -l \"$f\"\n",
    "; \n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Also see\n",
    "\n",
    "The **tee command** copies standard input to standard output and also to any files given as arguments. This is useful when you want not only to send some data down a pipe, but also to save a copy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
